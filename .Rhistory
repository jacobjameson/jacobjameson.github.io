# Calculate the differences in cost and QALYs
merged <- merged %>%
mutate(
Cost_diff = c(Cost[1], diff(Cost)),
Qaly_diff = c(Qaly[1], diff(Qaly)),
ICER = Cost_diff / Qaly_diff
)
# Check for negative ICERs
if (any(merged$ICER < 0, na.rm = TRUE)) {
# Filter out the surgery with negative ICER
merged <- merged %>% filter(!(ICER < 0 & !is.na(ICER)))
} else {
negative_icer <- FALSE
}
}
merged$group <- i
icers <- rbind(icers, merged[, c('Surgery', 'ICER', 'group')])
}
View(icers)
#plot icers for each group
ggplot(icers, aes(y = ICER, x = group, color = Surgery)) +
geom_point() +
geom_line() +
theme_bw() +
theme(legend.position = 'right') +
labs(title = 'ICERs for each group', x = 'Surgery', y = 'ICER')
icers <- filter(icers, Surgery != 'V0')
#plot icers for each group
ggplot(icers, aes(y = ICER, x = group, color = Surgery)) +
geom_point() +
geom_line() +
theme_bw() +
theme(legend.position = 'right') +
labs(title = 'ICERs for each group', x = 'Surgery', y = 'ICER')
# Calculate the proportion of times each surgery is optimal
optimal_surgery <- icers %>%
group_by(group) %>%
filter(ICER == min(ICER)) %>%
count(Surgery) %>%
mutate(proportion = n / sum(n))
optimal_surgery
# calculate the proportion of ICERs that are negative
icers %>%
group_by(group) %>%
summarize(negative_ICER = sum(ICER < 0) / n())
icers
# Create a sequence for the range of WTP thresholds
wtp_thresholds <- seq(0, 60000, by = 1000)
# Initialize a list to store the preferred surgery at each WTP threshold
preferred_surgeries <- lapply(wtp_thresholds, function(wtp) {
# For each WTP, initialize a vector to store the preferred surgery for each group
preferred_for_wtp <- integer(nrow(icers) / length(unique(icers$Surgery)))
for (group in unique(icers$group)) {
group_icers <- subset(icers, group == group)
# Filter surgeries with ICER less than or equal to WTP and get the one with the maximum QALY
affordable_surgeries <- subset(group_icers, ICER <= wtp)
if (nrow(affordable_surgeries) > 0) {
preferred_surgery <- affordable_surgeries[which.max(affordable_surgeries$ICER), "Surgery"]
} else {
preferred_surgery <- NA  # No preferred surgery if none are affordable
}
preferred_for_wtp[group] <- preferred_surgery
}
# Return the preferred surgeries for this WTP threshold
table(factor(preferred_for_wtp, levels = unique(icers$Surgery)))
})
# Convert the list to a data frame for easier analysis and plotting
preferred_surgery_df <- do.call(rbind, preferred_surgeries)
rownames(preferred_surgery_df) <- wtp_thresholds
# Convert to long format for plotting
preferred_surgery_long <- reshape2::melt(preferred_surgery_df, variable.name = "Surgery", value.name = "Count")
preferred_surgery_long$WTP <- rep(wtp_thresholds, each = ncol(preferred_surgery_df))
# Calculate the percentage for each WTP and surgery
preferred_surgery_long$Percentage <- with(preferred_surgery_long, Count / sum(Count) * 100)
# Plot the percentage of times each surgery is preferred at each WTP threshold
ggplot(preferred_surgery_long, aes(x = WTP, y = Percentage, color = Surgery)) +
geom_line() +
labs(title = "Percentage of Times Each Surgery is Preferred at WTP Thresholds",
x = "Willingness-to-Pay (WTP) Threshold",
y = "Percentage Preferred") +
theme_minimal()
preferred_surgery_long
View(preferred_surgery_long)
# Create a sequence for the range of WTP thresholds
wtp_thresholds <- seq(0, 60000, by = 1000)
# Initialize a list to store the preferred surgery at each WTP threshold
preferred_surgeries <- lapply(wtp_thresholds, function(wtp) {
# For each WTP, initialize a vector to store the preferred surgery for each group
preferred_for_wtp <- integer(nrow(icers) / length(unique(icers$Surgery)))
for (group in unique(icers$group)) {
group_icers <- subset(icers, group == group)
# Filter surgeries with ICER less than or equal to WTP and get the one with the maximum QALY
affordable_surgeries <- subset(group_icers, ICER <= wtp)
if (nrow(affordable_surgeries) > 0) {
preferred_surgery <- affordable_surgeries[which.max(affordable_surgeries$ICER), "Surgery"]
} else {
preferred_surgery <- NA  # No preferred surgery if none are affordable
}
preferred_for_wtp[group] <- preferred_surgery
}
# Return the preferred surgeries for this WTP threshold
table(factor(preferred_for_wtp, levels = unique(icers$Surgery)))
})
View(preferred_surgeries)
# Convert the list to a data frame for easier analysis and plotting
preferred_surgery_df <- do.call(rbind, preferred_surgeries)
View(preferred_surgery_df)
rownames(preferred_surgery_df) <- wtp_thresholds
# Convert to long format for plotting
preferred_surgery_long <- reshape2::melt(preferred_surgery_df, variable.name = "Surgery", value.name = "Count")
preferred_surgery_long$WTP <- rep(wtp_thresholds, each = ncol(preferred_surgery_df))
library(ISLR)
college_data <- College
library(dplyr)
transformed_data <- college_data %>%
mutate(accept_rate = Accept/Apps) %>%
select(accept_rate, Outstate, Private)
library(dplyr)
transformed_data <- college_data %>%
mutate(accept_rate = Accept/Apps) %>%
select(accept_rate, Outstate, Private)
transformed_data <- transformed_data %>%
mutate(accept_rate = scale(accept_rate),
Outstate = scale(Outstate))
transformed_data
set.seed(222)
small_data <- transformed_data[sample(1:nrow(transformed_data), 100),]
x <- as.matrix(small_data[, 1:2])
y <- if_else(small_data[, 3] == "Yes", 1, -1)
summary(transformed_data)
plot(small_data[, c("accept_rate", "Outstate")],
col = small_data$Private)
# install.packages("e1071")
library(e1071)
college_svm1 <- svm(Private ~ Outstate + accept_rate,
data = small_data,
kernel = "linear",
cost = 10,
scale = FALSE)
plot(college_svm1, small_data)
summary(college_svm1)
college_svm1$index
beta <- drop(t(college_svm1$coefs) %*% x[college_svm1$index,])
beta0 <- -college_svm1$rho
print(beta)
print(beta0)
make.grid = function(x, n = 75) {
grange <-  apply(x, 2, range)
x1 <- seq(from = grange[1, 1], to = grange[2, 1], length = n)
x2 <- seq(from = grange[1, 2], to = grange[2, 2], length = n)
expand.grid(X1 = x1, X2 = x2)
}
xgrid <- make.grid(x)
colnames(xgrid) <- colnames(x)
ygrid <- predict(college_svm1, xgrid)
plot(xgrid,
col = c("red","blue")[as.numeric(ygrid)],
pch = 20,
cex = .2)
points(x,
col = y + 3,
pch = 19)
points(x[college_svm1$index,],
pch = 5,
cex = 2)
abline(-beta0 / beta[2], -beta[1]/beta[2])
plot(xgrid,
col = c("red","blue")[as.numeric(ygrid)],
pch = 20,
cex = .2)
points(x,
col = y + 3,
pch = 19)
points(x[college_svm1$index,],
pch = 5,
cex = 2)
abline(-beta0 / beta[2], -beta[1]/beta[2])
plot(xgrid,
col = c("red","blue")[as.numeric(ygrid)],
pch = 20,
cex = .2)
points(x,
col = y + 3,
pch = 19)
points(x[college_svm1$index,],
pch = 5,
cex = 2)
abline((-1 - beta0) / beta[2], -beta[1] / beta[2], lty = 2)
abline((+1 - beta0) / beta[2], -beta[1] / beta[2], lty = 2)
svm_cost <- function(df, cost_val, xgrid) {
svmfit <- svm(Private ~ Outstate + accept_rate,
data = df,
kernel = "linear",
cost = cost_val,
scale = FALSE)
print(paste("# of support vectors =", length(svmfit$index)))
beta <- drop(t(svmfit$coefs) %*% x[svmfit$index,])
beta0 <- -svmfit$rho
ygrid <- predict(svmfit, xgrid)
plot(xgrid, col = c("red","blue")[as.numeric(ygrid)], pch = 20, cex = .2)
points(x, col = y + 3, pch = 19)
points(x[df$index,], pch = 5, cex = 2)
abline(-beta0 / beta[2], -beta[1]/beta[2])
abline((-1 - beta0) / beta[2], -beta[1] / beta[2], lty = 2)
abline((+1 - beta0) / beta[2], -beta[1] / beta[2], lty = 2)
}
svm_cost(small_data, .01, xgrid)
set.seed(222)
tune_linear <- tune(svm,
Private ~ accept_rate + Outstate,
data = transformed_data,
kernel = "linear",
ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
summary(tune_linear)
best_linear_mod <- tune_linear$best.model
summary(best_linear_mod)
tune_linear_full <- tune(svm,
Private ~ .,
data = college_data,
kernel = "linear",
ranges = list(cost = c(0.001, 0.01, 0.1,
1, 5, 10, 100)))
summary(tune_linear_full)
svm_poly3 <- svm(Private ~ Outstate + accept_rate,
data = small_data,
kernel = "polynomial",
degree = 3,
cost = 1)
plot(svm_poly3, small_data)
ygrid <- predict(svm_poly3, xgrid)
plot(xgrid, col = c("red","blue")[as.numeric(ygrid)],
pch = 20, cex = .2)
points(x, col = y + 3, pch = 19)
predicted_grid <- predict(svm_poly3, xgrid,
decision.values = TRUE)
predicted_grid <- attributes(predicted_grid)$decision
contour(unique(xgrid[,1]), unique(xgrid[,2]),
matrix(predicted_grid, 75, 75),
level = 0,
add = TRUE)
ygrid <- predict(svm_poly3, xgrid)
plot(xgrid, col = c("red","blue")[as.numeric(ygrid)],
pch = 20, cex = .2)
points(x, col = y + 3, pch = 19)
contour(unique(xgrid[,1]), unique(xgrid[,2]),
matrix(predicted_grid, 75, 75),
level = 0,
add = TRUE)
set.seed(222)
tune_poly <- tune(svm,
Private ~ .,
data = transformed_data,
kernel = "polynomial",
ranges = list(cost = c(0.001, 0.1, 1, 5, 100),
degree = c(2, 3)))
summary(tune_poly)
set.seed(222)
tune_radial <- tune(svm, Private ~ .,
data = transformed_data,
kernel = "radial",
ranges = list(cost = c(0.001, 0.1, 1, 5, 100),
gamma = c(0.0001, 0.001, 0.01, 0.1, 1)))
summary(tune_radial)
svm_radial <- tune_radial$best.model
## Make predictions for the xgrid
ygrid <- predict(svm_radial, xgrid)
## And plot the grid predictions and decision boundary
plot(xgrid, col = c("red","blue")[as.numeric(ygrid)],
pch = 20, cex = .2)
points(x, col = y + 3, pch = 19)
predicted_grid <- predict(svm_radial, xgrid, decision.values = TRUE)
predicted_grid <- attributes(predicted_grid)$decision
contour(unique(xgrid[,1]), unique(xgrid[,2]),
matrix(predicted_grid, 75, 75), level = 0, add = TRUE)
full_poly <- tune(svm,
Private ~ .,
data = college_data,
kernel = "polynomial",
ranges = list(cost = c(0.001, 0.1, 1, 5, 100),
degree = c(2, 3)))
summary(full_poly)
summary(tune_poly)
full_radial <- tune(svm,
Private ~ .,
data = college_data,
kernel = "radial",
ranges = list(cost = c(0.001, 0.1, 1, 5, 100),
gamma = c(0.0001, 0.001, 0.01, 0.1, 1)))
summary(full_radial)
summary(tune_radial)
library(ISLR)
college_data <- College
library(dplyr)
transformed_data <- college_data %>%
mutate(accept_rate = Accept/Apps) %>%
select(accept_rate, Outstate, Private)
transformed_data <- transformed_data %>%
mutate(accept_rate = scale(accept_rate),
Outstate = scale(Outstate))
set.seed(222)
small_data <- transformed_data[sample(1:nrow(transformed_data), 100),]
x <- as.matrix(small_data[, 1:2])
y <- if_else(small_data[, 3] == "Yes", 1, -1)
summary(transformed_data)
plot(small_data[, c("accept_rate", "Outstate")],
col = small_data$Private)
# install.packages("e1071")
library(e1071)
college_svm1 <- svm(Private ~ Outstate + accept_rate,
data = small_data,
kernel = "linear",
cost = 10,
scale = FALSE)
plot(college_svm1, small_data)
summary(college_svm1)
college_svm1$index
beta <- drop(t(college_svm1$coefs) %*% x[college_svm1$index,])
beta0 <- -college_svm1$rho
print(beta)
print(beta0)
make.grid = function(x, n = 75) {
grange <-  apply(x, 2, range)
x1 <- seq(from = grange[1, 1], to = grange[2, 1], length = n)
x2 <- seq(from = grange[1, 2], to = grange[2, 2], length = n)
expand.grid(X1 = x1, X2 = x2)
}
xgrid <- make.grid(x)
colnames(xgrid) <- colnames(x)
ygrid <- predict(college_svm1, xgrid)
plot(xgrid,
col = c("red","blue")[as.numeric(ygrid)],
pch = 20,
cex = .2)
points(x,
col = y + 3,
pch = 19)
points(x[college_svm1$index,],
pch = 5,
cex = 2)
plot(xgrid,
col = c("red","blue")[as.numeric(ygrid)],
pch = 20,
cex = .2)
points(x,
col = y + 3,
pch = 19)
points(x[college_svm1$index,],
pch = 5,
cex = 2)
abline(-beta0 / beta[2], -beta[1]/beta[2])
plot(xgrid,
col = c("red","blue")[as.numeric(ygrid)],
pch = 20,
cex = .2)
points(x,
col = y + 3,
pch = 19)
points(x[college_svm1$index,],
pch = 5,
cex = 2)
abline((-1 - beta0) / beta[2], -beta[1] / beta[2], lty = 2)
abline((+1 - beta0) / beta[2], -beta[1] / beta[2], lty = 2)
svm_cost <- function(df, cost_val, xgrid) {
svmfit <- svm(Private ~ Outstate + accept_rate,
data = df,
kernel = "linear",
cost = cost_val,
scale = FALSE)
print(paste("# of support vectors =", length(svmfit$index)))
beta <- drop(t(svmfit$coefs) %*% x[svmfit$index,])
beta0 <- -svmfit$rho
ygrid <- predict(svmfit, xgrid)
plot(xgrid, col = c("red","blue")[as.numeric(ygrid)], pch = 20, cex = .2)
points(x, col = y + 3, pch = 19)
points(x[df$index,], pch = 5, cex = 2)
abline(-beta0 / beta[2], -beta[1]/beta[2])
abline((-1 - beta0) / beta[2], -beta[1] / beta[2], lty = 2)
abline((+1 - beta0) / beta[2], -beta[1] / beta[2], lty = 2)
}
svm_cost(small_data, .01, xgrid)
svm_cost(small_data, .1, xgrid)
set.seed(222)
tune_linear <- tune(svm,
Private ~ accept_rate + Outstate,
data = transformed_data,
kernel = "linear",
ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
summary(tune_linear)
best_linear_mod <- tune_linear$best.model
summary(best_linear_mod)
summary(tune_linear)
tune_linear_full <- tune(svm,
Private ~ .,
data = college_data,
kernel = "linear",
ranges = list(cost = c(0.001, 0.01, 0.1,
1, 5, 10, 100)))
summary(tune_linear_full)
svm_poly3 <- svm(Private ~ Outstate + accept_rate,
data = small_data,
kernel = "polynomial",
degree = 3,
cost = 1)
plot(svm_poly3, small_data)
ygrid <- predict(svm_poly3, xgrid)
plot(xgrid, col = c("red","blue")[as.numeric(ygrid)],
pch = 20, cex = .2)
points(x, col = y + 3, pch = 19)
predicted_grid <- predict(svm_poly3, xgrid,
decision.values = TRUE)
predicted_grid <- attributes(predicted_grid)$decision
ygrid <- predict(svm_poly3, xgrid)
plot(xgrid, col = c("red","blue")[as.numeric(ygrid)],
pch = 20, cex = .2)
points(x, col = y + 3, pch = 19)
contour(unique(xgrid[,1]), unique(xgrid[,2]),
matrix(predicted_grid, 75, 75),
level = 0,
add = TRUE)
set.seed(222)
tune_poly <- tune(svm,
Private ~ .,
data = transformed_data,
kernel = "polynomial",
ranges = list(cost = c(0.001, 0.1, 1, 5, 100),
degree = c(2, 3, 4)))
summary(tune_poly)
set.seed(222)
tune_radial <- tune(svm, Private ~ .,
data = transformed_data,
kernel = "radial",
ranges = list(cost = c(0.001, 0.1, 1, 5, 100),
gamma = c(0.0001, 0.001, 0.01, 0.1, 1)))
summary(tune_radial)
svm_radial <- tune_radial$best.model
## Make predictions for the xgrid
ygrid <- predict(svm_radial, xgrid)
## And plot the grid predictions and decision boundary
plot(xgrid, col = c("red","blue")[as.numeric(ygrid)],
pch = 20, cex = .2)
points(x, col = y + 3, pch = 19)
predicted_grid <- predict(svm_radial, xgrid, decision.values = TRUE)
predicted_grid <- attributes(predicted_grid)$decision
contour(unique(xgrid[,1]), unique(xgrid[,2]),
matrix(predicted_grid, 75, 75), level = 0, add = TRUE)
full_poly <- tune(svm,
Private ~ .,
data = college_data,
kernel = "polynomial",
ranges = list(cost = c(0.001, 0.1, 1, 5, 100),
degree = c(2, 3)))
summary(full_poly)
summary(tune_poly)
full_radial <- tune(svm,
Private ~ .,
data = college_data,
kernel = "radial",
ranges = list(cost = c(0.001, 0.1, 1, 5, 100),
gamma = c(0.0001, 0.001, 0.01, 0.1, 1)))
summary(full_radial)
summary(tune_radial)
summary(full_poly)
summary(tune_poly)
summary(full_radial)
summary(tune_radial)
View(college_data)
college_data[,-c(1)]
college_data[,-c(1)]
View(college_data)
college_data[,-c(1)] <- scale(college_data[,-c(1)])
full_radial <- tune(svm,
Private ~ .,
data = college_data,
kernel = "radial",
ranges = list(cost = c(0.001, 0.1, 1, 5, 100),
gamma = c(0.0001, 0.001, 0.01, 0.1, 1)))
summary(full_radial)
View(college_data)
?tune
?svm
# Load the data
handwriting <- read.csv("DARWIN.csv")
handwriting <- handwriting[, -1]
handwriting$class <- as.factor(handwriting$class)
# Split the data
set.seed(222)
train_index <- sample(1:nrow(handwriting), nrow(handwriting) * 0.7)
train <- handwriting[train_index, ]
test <- handwriting[-train_index, ]
# Run a decision tree
library(tree)
# Fit the tree
tree_fit <- tree(class ~ ., data = train)
# Cross-validation
cv_tree <- cv.tree(tree_fit, FUN = prune.misclass)
# Run a random forest
library(randomForest)
# Fit the random forest
rf_fit <- randomForest(class ~ ., data = train, ntree = 5000, importance = TRUE)
# Test error
rf_pred <- predict(rf_fit, newdata = test, type = "class")
mean(rf_pred != test$class)
# Recode the class variable
train$class <- ifelse(train$class == "H", 0, 1)
test$class <- ifelse(test$class == "H", 0, 1)
# Run a boosting model
library(gbm)
# Fit the boosting model
boost_fit <- gbm(class ~ ., data = train,
distribution = "bernoulli",
n.trees = 5000,
interaction.depth = 4)
