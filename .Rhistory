fill = "Predicted Species",
color = "Actual Species") +
theme_bw()
head(iris)
install.packages("ISLR")
print('jello')
library(ISLR)
data(College)
college_data  <- College
colnames(college_data)
View(college_data)
college_data  <- data(College)
data(College)
college_data  <- College
dim(college_data)
View(college_data)
college_data <- college_data[, -c(15, 2)]
to_drop <- which(names(college_data) %in% c("Apps", "S.F.Ratio"))
print(to_drop)
college_data <- College
to_drop <- which(names(college_data) %in% c("Apps", "S.F.Ratio"))
print(to_drop)
to_drop <- rev(to_drop)
print(to_drop)
college_data <- college_data[, -c(to_drop)]
str(college_data)
college_data$Private <- as.numeric(college_data$Private) - 1
summary(college_data$Private)
summary(college_data$Private)
summary(College$Private)
college_data <- College
set.seed(222)
nrow(college_data)
1:(nrow(college_data))
0.2 * nrow(college_data)
round(0.2 * nrow(college_data))
test_ids <- sample(1:(nrow(college_data)), round(0.2 * nrow(college_data)))
test_ids
training_ids <- which(!(1:(nrow(college_data)) %in% test_ids))
training_ids
test_data <- college_data[test_ids,]
training_data <- college_data[training_ids,]
library(class)
library(class)
knn_model1 <- knn(train = training_data[, -1],
test = test_data[, -1],
cl = training_data[, 1],
k = 1)
knn_model9 <- knn(train = training_data[, -1],
test = test_data[, -1],
cl = training_data[, 1],
k = 9)
?knn
knn_model9 <- knn(train = training_data[, -1],
test = test_data[, -1],
cl = training_data$Private,
k = 9)
knn_model1 <- knn(train = training_data[, -1],
test = test_data[, -1],
cl = training_data$Private,
k = 1)
knn_model9 <- knn(train = training_data[, -1],
test = test_data[, -1],
cl = training_data$Private,
k = 9)
knn_model1
knn_model1
testing_data$Private
test_data$Private
knn_model1
test_data$Private
which(knn_model1 == test_data$Private)
length(which(knn_model1 == test_data$Private))
length(which(knn_model1 == test_data$Private))/nrow(test_data)
accuracy1  <- length(which(knn_model1 == test_data$Private)) / nrow(test_data)
accuracy9 <- length(which(knn_model9 == test_data$Private)) / nrow(test_data)
print(accuracy1)
print(accuracy9)
library(ggplot2)
ggplot(data = training_data,
aes(x = Outstate, y = F.Undergrad,
color = as.factor(Private))) +
geom_point() +
geom_point(data = test_data, aes(x = Outstate, y = F.Undergrad),
color = "black", size = 1) +
scale_color_manual(values = c("red", "blue")) +
theme_minimal() +
guides(color = guide_legend(title = "Private"))
print(length(which(test_data$Private == "Yes")) / nrow(test_data))
private_schools <- which(test_data$Private == "Yes")
public_schools <- which(test_data$Private == "No")
print(private_schools)
print(public_schools)
library(ISLR)
data(College)
college_data  <- College
colnames(college_data)
dim(college_data)
college_data <- college_data[, -c(15, 2)]
college_data <- College
college_data <- college_data[, -c(2)]
college_data <- college_data[, -c(15)]
college_data <- College
to_drop <- which(names(college_data) %in% c("Apps", "S.F.Ratio"))
print(to_drop)
to_drop <- rev(to_drop)
print(to_drop)
college_data <- college_data[, -c(to_drop)]
str(college_data)
college_data$Private <- as.numeric(college_data$Private) - 1
summary(college_data$Private)
summary(College$Private)
college_data <- College
set.seed(222)
test_ids <- sample(1:(nrow(college_data)), round(0.2 * nrow(college_data)))
test_ids
training_ids <- which(!(1:(nrow(college_data)) %in% test_ids))
training_ids
test_data <- college_data[test_ids,]
training_data <- college_data[training_ids,]
library(class)
knn_model1 <- knn(train = training_data[, -1],
test = test_data[, -1],
cl = training_data$Private,
k = 1)
knn_model9 <- knn(train = training_data[, -1],
test = test_data[, -1],
cl = training_data$Private,
k = 9)
accuracy1  <- length(which(knn_model1 == test_data$Private)) / nrow(test_data)
accuracy9 <- length(which(knn_model9 == test_data$Private)) / nrow(test_data)
print(accuracy1)
print(accuracy9)
library(ggplot2)
ggplot(data = training_data,
aes(x = Outstate, y = F.Undergrad,
color = as.factor(Private))) +
geom_point() +
geom_point(data = test_data, aes(x = Outstate, y = F.Undergrad),
color = "black", size = 1) +
scale_color_manual(values = c("red", "blue")) +
theme_minimal() +
guides(color = guide_legend(title = "Private"))
print(length(which(test_data$Private == "Yes")) / nrow(test_data))
private_accuracy1 <- length(
which(knn_model1[private_schools] == test_data$Private[private_schools])) /
num_private_schools
#install.packages("FNN")
library(FNN)
knn_reg1 <- knn.reg(training_data[, -c(1, 4)],
test_data[, -c(1, 4)],
training_data$Enroll,
k = 1)
knn_reg5 <- knn.reg(training_data[, -c(1, 4)],
test_data[,-c(1, 4)],
training_data$Enroll,
k = 5)
knn_reg1
knn_reg1$pred
mse_knn1 <- mean((knn_reg1$pred - test_data$Enroll)^2)
mse_knn5 <- mean((knn_reg5$pred - test_data$Enroll)^2)
mse_knn1 <- mean((knn_reg1$pred - test_data$Enroll)^2)
mse_knn5 <- mean((knn_reg5$pred - test_data$Enroll)^2)
print(mse_knn1)
print(mse_knn5)
enroll_reg <- lm(Enroll ~ ., training_data)
enroll_reg$coefficients
summary(enroll_reg)
predicted_enroll <- predict(enroll_reg, test_data[, -4])
MSE_lm_enroll <- mean((predicted_enroll - test_data$Enroll)^2)
print(MSE_lm_enroll)
print(mean((enroll_reg$residuals)^2))
print(mean((enroll_reg$residuals)^2) / MSE_lm_enroll)
```{r}
73296.56-39312.19
# We need the ISLR library for the dataset
library(ISLR)
# We need this library to perfom KNN
library(FNN)
# Here, we also use the data.table package,
# which is great for certain data cleaning/manipulation operations
# For more information, please check the documentation/vignette of the package
library(data.table)
#| code-fold: true
#| hide-output
#| code-summary: "Sample Solution"
# Store the data in a clean object and cast the data into a "data.table" object
# As noted earlier this package simplifies some of the data cleaning...
credit_data  <- as.data.table(Credit)
#| code-fold: true
#| hide-output
#| code-summary: "Sample Solution"
dim(credit_data)
#| code-fold: true
#| code-summary: "Sample Solution"
str(credit_data)
#| code-fold: true
#| code-summary: "Sample Solution"
nrow(credit_data[!complete.cases(credit_data),])
#| code-fold: true
#| code-summary: "Sample Solution"
summary(credit_data)
#| code-fold: true
#| code-summary: "Sample Solution"
summary(credit_data)
#| code-fold: true
#| code-summary: "Sample Solution"
round(mean(credit_data$Income, na.rm = TRUE), 2)
#| code-fold: true
#| code-summary: "Sample Solution"
summary(credit_data)
#| code-fold: true
#| code-summary: "Sample Solution"
round(sd(credit_data$Income, na.rm = TRUE), 2)
#| code-fold: true
#| code-summary: "Sample Solution"
mod1 <- lm(Balance ~ Income, credit_data)
summary(mod1)
#| code-fold: true
#| code-summary: "Sample Solution"
mod2 <- lm(Balance ~ Income + Gender, credit_data)
summary(mod2)
#| code-fold: true
#| code-summary: "Sample Solution"
# Library for KNN regression
library(FNN)
# The model
knn_reg1 <- knn.reg(training_data[, -c(7)],
test_data[, -c(7)],
training_data$Balance,
k = 1)
#| code-fold: true
#| code-summary: "Sample Solution"
# The model
mod5 <- lm(Balance ~ ., training_data)
#| code-fold: true
#| code-summary: "Sample Solution"
# Set a seed
set.seed(222)
# Extract the random test and training IDs
test_ids <- sample(seq(nrow(credit_data_complete)),
round(0.25 * nrow(credit_data_complete)))
#| code-fold: true
#| code-summary: "Sample Solution"
# Remove rows with non-missing values
credit_data_complete <- credit_data[complete.cases(credit_data), ]
# Drop the district and municipality variables
credit_data_complete[, c("ID", "Gender", "Student",
"Married", "Ethnicity") := NULL] # "data.table" syntax
#| code-fold: true
#| code-summary: "Sample Solution"
# Set a seed
set.seed(222)
# Extract the random test and training IDs
test_ids <- sample(seq(nrow(credit_data_complete)),
round(0.25 * nrow(credit_data_complete)))
training_ids <- which(!(seq(nrow(credit_data_complete)) %in% test_ids))
# Now use the IDs to get the two sets
test_data <- credit_data_complete[test_ids,]
training_data <- credit_data_complete[training_ids,]
#| code-fold: true
#| code-summary: "Sample Solution"
# The model
mod5 <- lm(Balance ~ ., training_data)
# Generate test predictions
predicted_bal <- predict(mod5, test_data[, -7])
## Let's see how well we did in terms of MSE
MSE_lm_bal <- mean((predicted_bal - test_data$Balance)^2)
print(MSE_lm_bal)
#| code-fold: true
#| code-summary: "Sample Solution"
# Library for KNN regression
library(FNN)
# The model
knn_reg1 <- knn.reg(training_data[, -c(7)],
test_data[, -c(7)],
training_data$Balance,
k = 1)
# The MSE
mse_knn1 <- mean((knn_reg1$pred - test_data$Balance)^2)
print(mse_knn1)
#| code-fold: true
#| code-summary: "Sample Solution"
# Define the range of K values to test
k_guesses <- 1:100
# Initialize a tracker for the MSE values for each K
mse_res <- NULL
# Now loop through all the values
for(i in 1:length(k_guesses)){
# For each value, run the model using the current K guess
knn_reg <- knn.reg(training_data[, -c(7)],
test_data[, -c(7)],
training_data$Balance,
k = k_guesses[i]) # key line here
# The MSE
mse_knn <- mean((knn_reg$pred - test_data$Balance)^2)
# Now update the tracker
mse_res[i] <- mse_knn
}
# Now plot the results
plot(x = k_guesses, y = mse_res, main = "MSE vs. K", xlab = "K", ylab = "MSE")
#| code-fold: true
#| code-summary: "Sample Solution"
# Find the K that gives the minimum MSE
which.min(mse_res)
# It looks like $K = 8$ would give you the lowest MSE in this case.
# Note: this result may be different from yours depending on how your sampling played out.
#| code-fold: true
#| code-summary: "Sample Solution"
mod4 <- lm(log(Balance + 0.0001) ~ log(Income)*Gender, credit_data)
summary(mod4)
#| code-fold: true
#| code-summary: "Sample Solution"
mod3 <- lm(Balance ~ Income*Gender, credit_data)
summary(mod3)
library(ISLR)
# We need the ISLR library for the dataset
library(ISLR)
# We need this library to perfom KNN
library(FNN)
# Here, we also use the data.table package,
# which is great for certain data cleaning/manipulation operations
# For more information, please check the documentation/vignette of the package
library(data.table)
#| code-fold: true
#| code-summary: "Sample Solution"
# - H0: the difference in balance between females and males
#   (after controlling for income) is 0, that is $\beta_{gender} = 0$.
# - Ha: the difference in balance between females and males
#   (after controlling for income) is different from 0, that is $\beta_{gender} \neq 0$.
# P-value suggests we cannot reject the NULL at any reasonable level of
# significance (1\%, 5\%, 10\%)
#| code-fold: true
#| code-summary: "Sample Solution"
# The $R^2$ is 0.2158 and the adjusted $R^2$ is 0.2098. In the model without the
# interaction term the $R^2$ was 0.2157, and the adjusted $R^2$ was 0.2117.
# The $R^2$ has increased as expected given we have a added a term.
# However, the adjusted adjusted $R^2$ has decreased suggesting the
# interaction term does not add value
# (when considering the complexity it adds to the model).
#| code-fold: true
#| code-summary: "Sample Solution"
# Set a seed
set.seed(222)
# Extract the random test and training IDs
test_ids <- sample(seq(nrow(credit_data_complete)),
round(0.25 * nrow(credit_data_complete)))
training_ids <- which(!(seq(nrow(credit_data_complete)) %in% test_ids))
# Now use the IDs to get the two sets
test_data <- credit_data_complete[test_ids,]
training_data <- credit_data_complete[training_ids,]
#| code-fold: true
#| code-summary: "Sample Solution"
# The model
mod5 <- lm(Balance ~ ., training_data)
# Generate test predictions
predicted_bal <- predict(mod5, test_data[, -7])
## Let's see how well we did in terms of MSE
MSE_lm_bal <- mean((predicted_bal - test_data$Balance)^2)
print(MSE_lm_bal)
# [1] 33096.38
#| code-fold: true
#| code-summary: "Sample Solution"
# Find the K that gives the minimum MSE
which.min(mse_res)
# It looks like $K = 8$ would give you the lowest MSE in this case.
# Note: this result may be different from yours depending on how your sampling played out.
library(tufte)
# invalidate cache when the tufte version changes
knitr::opts_chunk$set(cache.extra = packageVersion('tufte'))
options(htmltools.dir.version = FALSE)
library(tidyverse)
males <- c('Jacob', 'Louis', 'Chris', 'Wyatt', 'Nolan', 'Robert',
'Zach', 'John','Bob', 'David', 'Avery', 'Ronald',
'Dallas', 'Dylan')
females <- c('Bohan', 'Jenna', 'Katarina', 'Hassina', 'Towo',
'Becca', 'Meredith', 'Gracie', 'Kayla', 'Marlene',
'Jade', 'Allyssa', 'Reigne', 'Wendy')
probs.diff.sex = c(0.15,0.15,0.05,0.05,0.1,0.1,0.05,0.1,0.01,0.09,0.05,0.05,0.025,0.025)
probs.same.sex = c(0.15,0.15,0.05,0.05,0.1,0.1,0.05,0.1,0.01,0.09,0.05,0.05,0.05)
set.seed(1997)
simulate.top.friends <- function(males, females, probs.diff.sex, probs.same.sex) {
dat <- setNames(data.frame(matrix(ncol = 6, nrow = 0)),
c("Ego", "Ego Sex", "MF1", "MF2", "FF1", "FF2"))
for (ego in males) {
temp.males <- males[! males %in% ego]
male.friends.i <- sample.int(13, 2, replace = FALSE, prob = probs.same.sex)
female.friends.i <- sample.int(14, 2, replace = FALSE, prob = probs.diff.sex)
male.friend.1 <- temp.males[male.friends.i[1]]
male.friend.2 <- temp.males[male.friends.i[2]]
female.friend.1 <- females[female.friends.i[1]]
female.friend.2 <- females[female.friends.i[2]]
dat[nrow(dat) + 1,] = c(ego, 'Male', male.friend.1, male.friend.2,
female.friend.1, female.friend.2)
}
for (ego in females) {
temp.females <- females[! females %in% ego]
male.friends.i <- sample.int(14, 2, replace = FALSE, prob = probs.diff.sex)
female.friends.i <- sample.int(13, 2, replace = FALSE, prob = probs.same.sex)
male.friend.1 <- males[male.friends.i[1]]
male.friend.2 <- males[male.friends.i[2]]
female.friend.1 <- temp.females[female.friends.i[1]]
female.friend.2 <- temp.females[female.friends.i[2]]
dat[nrow(dat) + 1,] = c(ego, 'Female', male.friend.1, male.friend.2,
female.friend.1, female.friend.2)
}
return(dat)
}
simulate.top.friends(males,females, probs.diff.sex, probs.same.sex)
library(kableExtra)
kbl(simulate.top.friends(males,females, probs.diff.sex, probs.same.sex)) %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
font_size = 10)
library(reshape)
friendships <- melt(simulate.top.friends(males,females,probs.diff.sex, probs.same.sex),
id=c("Ego", "Ego Sex")) %>%
select(source=Ego, source_sex =`Ego Sex`, target=value) %>%
arrange(source)
library(reshape)
friendships <- melt(simulate.top.friends(males,females,probs.diff.sex, probs.same.sex),
id=c("Ego", "Ego Sex")) %>%
select(source=Ego, source_sex =`Ego Sex`, target=value) %>%
arrange(source)
head(friendships, 10)
kbl(head(friendships, 10)) %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
font_size = 10)
library(igraph)
install.packages('igraph')
library(igraph)
install.packages("igraph", type="binary")
network <- graph_from_data_frame(friendships[,c('source','target','source_sex')],
directed = TRUE)
options(
repos = c(
igraph = 'https://igraph.r-universe.dev',
CRAN = 'https://cloud.r-project.org'
)
)
install.packages('igraph')
pak::pak("igraph/rigraph")
install.packages('pak')
pak::pak("igraph/rigraph")
# Load the data
data <- read.csv("data/heartRisk.csv")
dim(data)
str(data)
m <- mean(data$Risk, na.rm = TRUE)
sd <- sd(data$Risk, na.rm = TRUE)
print(paste("Mean:", round(m,2), "Standard Deviation:", round(sd,2)))
plot(data$Age, data$Risk,
xlab = "Cholesterol",
ylab = "ASCVD Risk",
main = "ASCVD Risk vs Cholesterol")
set.seed(222)
test <- sample(1:1000, 200)
train <- setdiff(1:1000, test)
train_data <- data[train,]
test_data <- data[test,]
library(stargazer)
model.1 <- lm(Risk ~ ., data = train_data)
test_pred <- predict(model.1, newdata = test_data)
test_mse <- mean((test_pred - test_data$Risk)^2)
test_mse
model.2 <- lm(Risk ~ Age + isDiabetic + isHypertensive, data = train_data)
test_pred <- predict(model.2, newdata = test_data)
test_mse <- mean((test_pred - test_data$Risk)^2)
test_mse
train_data[, -1]
library(FNN)
model.3 <- knn.reg(train = train_data[, -9],
test = test_data[, -9],
y = train_data$Risk, k = 2)
test_mse <- mean((model.3$pred - test_data$Risk)^2)
test_mse
model.4 <- knn.reg(train = train_data[, -9],
test = test_data[, -9],
y = train_data$Risk, k = 10)
test_mse <- mean((model.4$pred - test_data$Risk)^2)
test_mse
set.seed(222)
test <- sample(1:1000, 200)
train <- setdiff(1:1000, test)
train_data <- data[train,]
test_data <- data[test,]
library(stargazer)
model.1 <- lm(Risk ~ ., data = train_data)
test_pred <- predict(model.1, newdata = test_data)
test_mse <- mean((test_pred - test_data$Risk)^2)
test_mse
model.2 <- lm(Risk ~ Age + isDiabetic + isHypertensive, data = train_data)
test_pred <- predict(model.2, newdata = test_data)
test_mse <- mean((test_pred - test_data$Risk)^2)
test_mse
library(FNN)
model.3 <- knn.reg(train = train_data[, -9],
test = test_data[, -9],
y = train_data$Risk, k = 2)
test_mse <- mean((model.3$pred - test_data$Risk)^2)
test_mse
train_data[, 9]
library(FNN)
model.3 <- knn.reg(train = train_data[, -9],
test = test_data[, -9],
y = train_data$Risk, k = 2)
test_mse <- mean((model.3$pred - test_data$Risk)^2)
test_mse
model.4 <- knn.reg(train = train_data[, -9],
test = test_data[, -9],
y = train_data$Risk, k = 10)
test_mse <- mean((model.4$pred - test_data$Risk)^2)
test_mse
