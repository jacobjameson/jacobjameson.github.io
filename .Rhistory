labs(title = "KNN Decision Boundaries with Test Data",
x = "Sepal Length",
y = "Sepal Width",
fill = "Predicted Species",
color = "Actual Species") +
theme_bw()
# Visualize the results
ggplot(data = test_data, aes(x = Sepal.Length, y = Sepal.Width)) +
geom_point(aes(color = Species, shape = PredictedSpecies), size = 3) +
scale_shape_manual(values = c(15, 17, 18)) + # Different shapes for actual vs. predicted
scale_color_manual(values = c('red', 'blue', 'green')) +
labs(title = "KNN Classification of Iris Species",
x = "Sepal Length",
y = "Sepal Width",
color = "Actual Species",
shape = "Predicted Species") +
theme_minimal()
library(ggplot2)
iris.data <- iris
# Scatter plot visualizing petal width and length grouped by species
scatter <- ggplot(iris.data, aes(x = Petal.Width, y = Petal.Length, color = Species)) +
geom_point(size = 3, alpha = 0.6) +
theme_classic() +
theme(legend.position = "right") +
ggtitle("Scatter Plot of Petal Dimensions by Species")
print(scatter)
# Boxplot visualizing variation in petal width between species
boxplot <- ggplot(iris.data, aes(x = Species, y = Petal.Width, fill = Species)) +
geom_boxplot() +
theme_classic() +
theme(legend.position = "none") +
ggtitle("Boxplot of Petal Width by Species")
print(boxplot)
set.seed(123) # For reproducibility
# Select features and species for simplicity
iris_simplified <- iris %>%
select(Sepal.Length, Sepal.Width, Species)
# Split data into training and test sets
sample_size <- nrow(iris_simplified) * 0.7 # 70% for training
training_indices <- sample(1:nrow(iris_simplified), sample_size)
training_data <- iris_simplified[training_indices, ]
test_data <- iris_simplified[-training_indices, ]
# Perform KNN classification with k = 3
knn_result <- knn(train = training_data[, 1:2],
test = test_data[, 1:2],
cl = training_data[, 3],
k = 3)
# Add the predictions to the test_data dataframe for plotting
test_data$PredictedSpecies <- as.factor(knn_result)
# Visualize the results
ggplot(data = test_data, aes(x = Sepal.Length, y = Sepal.Width)) +
geom_point(aes(color = Species, shape = PredictedSpecies), size = 3) +
scale_shape_manual(values = c(15, 17, 18)) + # Different shapes for actual vs. predicted
scale_color_manual(values = c('red', 'blue', 'green')) +
labs(title = "KNN Classification of Iris Species",
x = "Sepal Length",
y = "Sepal Width",
color = "Actual Species",
shape = "Predicted Species") +
theme_minimal()
ggplot() +
geom_tile(data = grid, aes(x = Sepal.Length, y = Sepal.Width, fill = Species), alpha = 0.5) +
geom_point(data = test_data, aes(x = Sepal.Length, y = Sepal.Width, color = PredictedSpecies), size = 2) +
scale_fill_manual(values = c('setosa' = 'red', 'versicolor' = 'blue', 'virginica' = 'green')) +
scale_color_manual(values = c('setosa' = 'red', 'versicolor' = 'blue', 'virginica' = 'green')) +
labs(title = "KNN Decision Boundaries with Test Data",
x = "Sepal Length",
y = "Sepal Width",
fill = "Predicted Species",
color = "Actual Species") +
theme_bw()
ggplot() +
geom_tile(data = grid, aes(x = Sepal.Length, y = Sepal.Width, fill = Species), alpha = 0.5) +
geom_point(data = test_data, aes(x = Sepal.Length, y = Sepal.Width, color = Species), size = 2) +
scale_fill_manual(values = c('setosa' = 'red', 'versicolor' = 'blue', 'virginica' = 'green')) +
scale_color_manual(values = c('setosa' = 'red', 'versicolor' = 'blue', 'virginica' = 'green')) +
labs(title = "KNN Decision Boundaries with Test Data",
x = "Sepal Length",
y = "Sepal Width",
fill = "Predicted Species",
color = "Actual Species") +
theme_bw()
# Visualize the results
ggplot(data = test_data, aes(x = Sepal.Length, y = Sepal.Width)) +
geom_point(aes(color = Species, shape = PredictedSpecies), size = 3) +
scale_shape_manual(values = c(15, 17, 18)) + # Different shapes for actual vs. predicted
scale_color_manual(values = c('red', 'blue', 'green')) +
labs(title = "KNN Classification of Iris Species",
x = "Sepal Length",
y = "Sepal Width",
color = "Actual Species",
shape = "Predicted Species") +
theme_minimal()
ggplot() +
geom_tile(data = grid, aes(x = Sepal.Length, y = Sepal.Width, fill = Species), alpha = 0.5) +
geom_point(data = test_data, aes(x = Sepal.Length, y = Sepal.Width, color = Species), size = 2) +
scale_fill_manual(values = c('setosa' = 'red', 'versicolor' = 'blue', 'virginica' = 'green')) +
scale_color_manual(values = c('setosa' = 'red', 'versicolor' = 'blue', 'virginica' = 'green')) +
labs(title = "KNN Decision Boundaries with Test Data",
x = "Sepal Length",
y = "Sepal Width",
fill = "Predicted Species",
color = "Actual Species") +
theme_bw()
# Initialize an empty data frame to store k values and theirerror rates
error_rates <- data.frame(k = integer(), error_rate = numeric())
# Initialize an empty data frame to store k values and theirerror rates
error_rates <- data.frame(k = integer(), error_rate = numeric())
# Loop through k values from 1 to 10
for (k in 1:10) {
# Apply KNN model
predicted_species <- knn(train = training_data[, 1:2],
test = test_data[, 1:2],
cl = training_data[, 3],
k = k)
# Compute the error rate
error_rate <- sum(predicted_species != test_data[, 3]) / nrow(test_data)
# Add the results to the error_rates data frame
error_rates <- rbind(error_rates, data.frame(k = k, error_rate = error_rate))
}
# Display the error rates
print(error_rates)
# Optionally, use kable from knitr package for a nicer table format in R Markdown
knitr::kable(error_rates, caption = "Error Rates for K=1 to 10")
# Plot the decision boundaries by coloring the grid
x_range <- seq(from = min(iris$Sepal.Length) - 0.5,
to = max(iris$Sepal.Length) + 0.5, by = 0.01)
y_range <- seq(from = min(iris$Sepal.Width) - 0.5,
to = max(iris$Sepal.Width) + 0.5, by = 0.01)
grid <- expand.grid(Sepal.Length = x_range, Sepal.Width = y_range)
# Predict species for each point in the grid
grid$Species <- knn(train = training_data[, 1:2],
test = grid,
cl = training_data[, 3],
k = 4)
# Convert grid predictions into a factor for coloring
grid$Species <- as.factor(grid$Species)
ggplot() +
geom_tile(data = grid, aes(x = Sepal.Length, y = Sepal.Width, fill = Species), alpha = 0.5) +
geom_point(data = test_data, aes(x = Sepal.Length, y = Sepal.Width, color = Species), size = 2) +
scale_fill_manual(values = c('setosa' = 'red', 'versicolor' = 'blue', 'virginica' = 'green')) +
scale_color_manual(values = c('setosa' = 'red', 'versicolor' = 'blue', 'virginica' = 'green')) +
labs(title = "KNN Decision Boundaries with Test Data",
x = "Sepal Length",
y = "Sepal Width",
fill = "Predicted Species",
color = "Actual Species") +
theme_bw()
head(iris)
install.packages("ISLR")
print('jello')
library(ISLR)
data(College)
college_data  <- College
colnames(college_data)
View(college_data)
college_data  <- data(College)
data(College)
college_data  <- College
dim(college_data)
View(college_data)
college_data <- college_data[, -c(15, 2)]
to_drop <- which(names(college_data) %in% c("Apps", "S.F.Ratio"))
print(to_drop)
college_data <- College
to_drop <- which(names(college_data) %in% c("Apps", "S.F.Ratio"))
print(to_drop)
to_drop <- rev(to_drop)
print(to_drop)
college_data <- college_data[, -c(to_drop)]
str(college_data)
college_data$Private <- as.numeric(college_data$Private) - 1
summary(college_data$Private)
summary(college_data$Private)
summary(College$Private)
college_data <- College
set.seed(222)
nrow(college_data)
1:(nrow(college_data))
0.2 * nrow(college_data)
round(0.2 * nrow(college_data))
test_ids <- sample(1:(nrow(college_data)), round(0.2 * nrow(college_data)))
test_ids
training_ids <- which(!(1:(nrow(college_data)) %in% test_ids))
training_ids
test_data <- college_data[test_ids,]
training_data <- college_data[training_ids,]
library(class)
library(class)
knn_model1 <- knn(train = training_data[, -1],
test = test_data[, -1],
cl = training_data[, 1],
k = 1)
knn_model9 <- knn(train = training_data[, -1],
test = test_data[, -1],
cl = training_data[, 1],
k = 9)
?knn
knn_model9 <- knn(train = training_data[, -1],
test = test_data[, -1],
cl = training_data$Private,
k = 9)
knn_model1 <- knn(train = training_data[, -1],
test = test_data[, -1],
cl = training_data$Private,
k = 1)
knn_model9 <- knn(train = training_data[, -1],
test = test_data[, -1],
cl = training_data$Private,
k = 9)
knn_model1
knn_model1
testing_data$Private
test_data$Private
knn_model1
test_data$Private
which(knn_model1 == test_data$Private)
length(which(knn_model1 == test_data$Private))
length(which(knn_model1 == test_data$Private))/nrow(test_data)
accuracy1  <- length(which(knn_model1 == test_data$Private)) / nrow(test_data)
accuracy9 <- length(which(knn_model9 == test_data$Private)) / nrow(test_data)
print(accuracy1)
print(accuracy9)
library(ggplot2)
ggplot(data = training_data,
aes(x = Outstate, y = F.Undergrad,
color = as.factor(Private))) +
geom_point() +
geom_point(data = test_data, aes(x = Outstate, y = F.Undergrad),
color = "black", size = 1) +
scale_color_manual(values = c("red", "blue")) +
theme_minimal() +
guides(color = guide_legend(title = "Private"))
print(length(which(test_data$Private == "Yes")) / nrow(test_data))
private_schools <- which(test_data$Private == "Yes")
public_schools <- which(test_data$Private == "No")
print(private_schools)
print(public_schools)
library(ISLR)
data(College)
college_data  <- College
colnames(college_data)
dim(college_data)
college_data <- college_data[, -c(15, 2)]
college_data <- College
college_data <- college_data[, -c(2)]
college_data <- college_data[, -c(15)]
college_data <- College
to_drop <- which(names(college_data) %in% c("Apps", "S.F.Ratio"))
print(to_drop)
to_drop <- rev(to_drop)
print(to_drop)
college_data <- college_data[, -c(to_drop)]
str(college_data)
college_data$Private <- as.numeric(college_data$Private) - 1
summary(college_data$Private)
summary(College$Private)
college_data <- College
set.seed(222)
test_ids <- sample(1:(nrow(college_data)), round(0.2 * nrow(college_data)))
test_ids
training_ids <- which(!(1:(nrow(college_data)) %in% test_ids))
training_ids
test_data <- college_data[test_ids,]
training_data <- college_data[training_ids,]
library(class)
knn_model1 <- knn(train = training_data[, -1],
test = test_data[, -1],
cl = training_data$Private,
k = 1)
knn_model9 <- knn(train = training_data[, -1],
test = test_data[, -1],
cl = training_data$Private,
k = 9)
accuracy1  <- length(which(knn_model1 == test_data$Private)) / nrow(test_data)
accuracy9 <- length(which(knn_model9 == test_data$Private)) / nrow(test_data)
print(accuracy1)
print(accuracy9)
library(ggplot2)
ggplot(data = training_data,
aes(x = Outstate, y = F.Undergrad,
color = as.factor(Private))) +
geom_point() +
geom_point(data = test_data, aes(x = Outstate, y = F.Undergrad),
color = "black", size = 1) +
scale_color_manual(values = c("red", "blue")) +
theme_minimal() +
guides(color = guide_legend(title = "Private"))
print(length(which(test_data$Private == "Yes")) / nrow(test_data))
private_accuracy1 <- length(
which(knn_model1[private_schools] == test_data$Private[private_schools])) /
num_private_schools
#install.packages("FNN")
library(FNN)
knn_reg1 <- knn.reg(training_data[, -c(1, 4)],
test_data[, -c(1, 4)],
training_data$Enroll,
k = 1)
knn_reg5 <- knn.reg(training_data[, -c(1, 4)],
test_data[,-c(1, 4)],
training_data$Enroll,
k = 5)
knn_reg1
knn_reg1$pred
mse_knn1 <- mean((knn_reg1$pred - test_data$Enroll)^2)
mse_knn5 <- mean((knn_reg5$pred - test_data$Enroll)^2)
mse_knn1 <- mean((knn_reg1$pred - test_data$Enroll)^2)
mse_knn5 <- mean((knn_reg5$pred - test_data$Enroll)^2)
print(mse_knn1)
print(mse_knn5)
enroll_reg <- lm(Enroll ~ ., training_data)
enroll_reg$coefficients
summary(enroll_reg)
predicted_enroll <- predict(enroll_reg, test_data[, -4])
MSE_lm_enroll <- mean((predicted_enroll - test_data$Enroll)^2)
print(MSE_lm_enroll)
print(mean((enroll_reg$residuals)^2))
print(mean((enroll_reg$residuals)^2) / MSE_lm_enroll)
```{r}
73296.56-39312.19
# We need the ISLR library for the dataset
library(ISLR)
# We need this library to perfom KNN
library(FNN)
# Here, we also use the data.table package,
# which is great for certain data cleaning/manipulation operations
# For more information, please check the documentation/vignette of the package
library(data.table)
#| code-fold: true
#| hide-output
#| code-summary: "Sample Solution"
# Store the data in a clean object and cast the data into a "data.table" object
# As noted earlier this package simplifies some of the data cleaning...
credit_data  <- as.data.table(Credit)
#| code-fold: true
#| hide-output
#| code-summary: "Sample Solution"
dim(credit_data)
#| code-fold: true
#| code-summary: "Sample Solution"
str(credit_data)
#| code-fold: true
#| code-summary: "Sample Solution"
nrow(credit_data[!complete.cases(credit_data),])
#| code-fold: true
#| code-summary: "Sample Solution"
summary(credit_data)
#| code-fold: true
#| code-summary: "Sample Solution"
summary(credit_data)
#| code-fold: true
#| code-summary: "Sample Solution"
round(mean(credit_data$Income, na.rm = TRUE), 2)
#| code-fold: true
#| code-summary: "Sample Solution"
summary(credit_data)
#| code-fold: true
#| code-summary: "Sample Solution"
round(sd(credit_data$Income, na.rm = TRUE), 2)
#| code-fold: true
#| code-summary: "Sample Solution"
mod1 <- lm(Balance ~ Income, credit_data)
summary(mod1)
#| code-fold: true
#| code-summary: "Sample Solution"
mod2 <- lm(Balance ~ Income + Gender, credit_data)
summary(mod2)
#| code-fold: true
#| code-summary: "Sample Solution"
# Library for KNN regression
library(FNN)
# The model
knn_reg1 <- knn.reg(training_data[, -c(7)],
test_data[, -c(7)],
training_data$Balance,
k = 1)
#| code-fold: true
#| code-summary: "Sample Solution"
# The model
mod5 <- lm(Balance ~ ., training_data)
#| code-fold: true
#| code-summary: "Sample Solution"
# Set a seed
set.seed(222)
# Extract the random test and training IDs
test_ids <- sample(seq(nrow(credit_data_complete)),
round(0.25 * nrow(credit_data_complete)))
#| code-fold: true
#| code-summary: "Sample Solution"
# Remove rows with non-missing values
credit_data_complete <- credit_data[complete.cases(credit_data), ]
# Drop the district and municipality variables
credit_data_complete[, c("ID", "Gender", "Student",
"Married", "Ethnicity") := NULL] # "data.table" syntax
#| code-fold: true
#| code-summary: "Sample Solution"
# Set a seed
set.seed(222)
# Extract the random test and training IDs
test_ids <- sample(seq(nrow(credit_data_complete)),
round(0.25 * nrow(credit_data_complete)))
training_ids <- which(!(seq(nrow(credit_data_complete)) %in% test_ids))
# Now use the IDs to get the two sets
test_data <- credit_data_complete[test_ids,]
training_data <- credit_data_complete[training_ids,]
#| code-fold: true
#| code-summary: "Sample Solution"
# The model
mod5 <- lm(Balance ~ ., training_data)
# Generate test predictions
predicted_bal <- predict(mod5, test_data[, -7])
## Let's see how well we did in terms of MSE
MSE_lm_bal <- mean((predicted_bal - test_data$Balance)^2)
print(MSE_lm_bal)
#| code-fold: true
#| code-summary: "Sample Solution"
# Library for KNN regression
library(FNN)
# The model
knn_reg1 <- knn.reg(training_data[, -c(7)],
test_data[, -c(7)],
training_data$Balance,
k = 1)
# The MSE
mse_knn1 <- mean((knn_reg1$pred - test_data$Balance)^2)
print(mse_knn1)
#| code-fold: true
#| code-summary: "Sample Solution"
# Define the range of K values to test
k_guesses <- 1:100
# Initialize a tracker for the MSE values for each K
mse_res <- NULL
# Now loop through all the values
for(i in 1:length(k_guesses)){
# For each value, run the model using the current K guess
knn_reg <- knn.reg(training_data[, -c(7)],
test_data[, -c(7)],
training_data$Balance,
k = k_guesses[i]) # key line here
# The MSE
mse_knn <- mean((knn_reg$pred - test_data$Balance)^2)
# Now update the tracker
mse_res[i] <- mse_knn
}
# Now plot the results
plot(x = k_guesses, y = mse_res, main = "MSE vs. K", xlab = "K", ylab = "MSE")
#| code-fold: true
#| code-summary: "Sample Solution"
# Find the K that gives the minimum MSE
which.min(mse_res)
# It looks like $K = 8$ would give you the lowest MSE in this case.
# Note: this result may be different from yours depending on how your sampling played out.
#| code-fold: true
#| code-summary: "Sample Solution"
mod4 <- lm(log(Balance + 0.0001) ~ log(Income)*Gender, credit_data)
summary(mod4)
#| code-fold: true
#| code-summary: "Sample Solution"
mod3 <- lm(Balance ~ Income*Gender, credit_data)
summary(mod3)
library(ISLR)
# We need the ISLR library for the dataset
library(ISLR)
# We need this library to perfom KNN
library(FNN)
# Here, we also use the data.table package,
# which is great for certain data cleaning/manipulation operations
# For more information, please check the documentation/vignette of the package
library(data.table)
#| code-fold: true
#| code-summary: "Sample Solution"
# - H0: the difference in balance between females and males
#   (after controlling for income) is 0, that is $\beta_{gender} = 0$.
# - Ha: the difference in balance between females and males
#   (after controlling for income) is different from 0, that is $\beta_{gender} \neq 0$.
# P-value suggests we cannot reject the NULL at any reasonable level of
# significance (1\%, 5\%, 10\%)
#| code-fold: true
#| code-summary: "Sample Solution"
# The $R^2$ is 0.2158 and the adjusted $R^2$ is 0.2098. In the model without the
# interaction term the $R^2$ was 0.2157, and the adjusted $R^2$ was 0.2117.
# The $R^2$ has increased as expected given we have a added a term.
# However, the adjusted adjusted $R^2$ has decreased suggesting the
# interaction term does not add value
# (when considering the complexity it adds to the model).
#| code-fold: true
#| code-summary: "Sample Solution"
# Set a seed
set.seed(222)
# Extract the random test and training IDs
test_ids <- sample(seq(nrow(credit_data_complete)),
round(0.25 * nrow(credit_data_complete)))
training_ids <- which(!(seq(nrow(credit_data_complete)) %in% test_ids))
# Now use the IDs to get the two sets
test_data <- credit_data_complete[test_ids,]
training_data <- credit_data_complete[training_ids,]
#| code-fold: true
#| code-summary: "Sample Solution"
# The model
mod5 <- lm(Balance ~ ., training_data)
# Generate test predictions
predicted_bal <- predict(mod5, test_data[, -7])
## Let's see how well we did in terms of MSE
MSE_lm_bal <- mean((predicted_bal - test_data$Balance)^2)
print(MSE_lm_bal)
# [1] 33096.38
#| code-fold: true
#| code-summary: "Sample Solution"
# Find the K that gives the minimum MSE
which.min(mse_res)
# It looks like $K = 8$ would give you the lowest MSE in this case.
# Note: this result may be different from yours depending on how your sampling played out.
