<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Jacob Jameson">

<title>Jacob Jameson - Section 2 - KNN and Linear Regression</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="twitter:title" content="Jacob Jameson - Section 2 - KNN and Linear Regression">
<meta name="twitter:description" content="">
<meta name="twitter:image" content="https://www.jacobjameson.com/api 222 files/section 2/images/profile.png">
<meta name="twitter:creator" content="@JacobCJameson">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../images/sig.png" alt="" class="navbar-logo">
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/jacob-jameson" rel="" target="_blank"><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/JacobCJameson" rel="" target="_blank"><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/jacobjameson" rel="" target="_blank"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../posts/blog.html" rel="" target="">
 <span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-teaching" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Teaching</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-teaching">    
        <li>
    <a class="dropdown-item" href="../../teaching.html" rel="" target="">
 <span class="dropdown-text">Jacob’s Teaching Experience</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../R files/Intro R.html" rel="" target="">
 <span class="dropdown-text">Introduction to R</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../git files/Intro Git.html" rel="" target="">
 <span class="dropdown-text">Introduction to Git/GitHub</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../api 222 files/API222.html" rel="" target="">
 <span class="dropdown-text">API 222 Section Material</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../research.html" rel="" target="">
 <span class="menu-text">Research</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#notes" id="toc-notes" class="nav-link active" data-scroll-target="#notes">Notes</a>
  <ul class="collapse">
  <li><a href="#important-machine-learning-concepts" id="toc-important-machine-learning-concepts" class="nav-link" data-scroll-target="#important-machine-learning-concepts">Important Machine Learning Concepts</a>
  <ul class="collapse">
  <li><a href="#regression-vs-classification" id="toc-regression-vs-classification" class="nav-link" data-scroll-target="#regression-vs-classification">Regression vs Classification</a></li>
  <li><a href="#bias-variance-trade-off" id="toc-bias-variance-trade-off" class="nav-link" data-scroll-target="#bias-variance-trade-off">Bias-Variance Trade-off</a></li>
  <li><a href="#supervised-v.-unsupervised-learning" id="toc-supervised-v.-unsupervised-learning" class="nav-link" data-scroll-target="#supervised-v.-unsupervised-learning">Supervised v. Unsupervised Learning</a></li>
  <li><a href="#measuring-model-performance" id="toc-measuring-model-performance" class="nav-link" data-scroll-target="#measuring-model-performance">Measuring Model Performance</a></li>
  </ul></li>
  <li><a href="#k-nearest-neighbors" id="toc-k-nearest-neighbors" class="nav-link" data-scroll-target="#k-nearest-neighbors">K-Nearest Neighbors</a>
  <ul class="collapse">
  <li><a href="#concept" id="toc-concept" class="nav-link" data-scroll-target="#concept">Concept</a></li>
  <li><a href="#method" id="toc-method" class="nav-link" data-scroll-target="#method">Method</a></li>
  <li><a href="#implementation-and-considerations" id="toc-implementation-and-considerations" class="nav-link" data-scroll-target="#implementation-and-considerations">Implementation and Considerations</a></li>
  <li><a href="#extensions" id="toc-extensions" class="nav-link" data-scroll-target="#extensions">Extensions</a></li>
  </ul></li>
  <li><a href="#linear-regression" id="toc-linear-regression" class="nav-link" data-scroll-target="#linear-regression">Linear Regression</a>
  <ul class="collapse">
  <li><a href="#concept-1" id="toc-concept-1" class="nav-link" data-scroll-target="#concept-1">Concept</a></li>
  <li><a href="#method-1" id="toc-method-1" class="nav-link" data-scroll-target="#method-1">Method</a></li>
  <li><a href="#implementation-and-considerations-1" id="toc-implementation-and-considerations-1" class="nav-link" data-scroll-target="#implementation-and-considerations-1">Implementation and Considerations</a></li>
  <li><a href="#comparison-to-knn" id="toc-comparison-to-knn" class="nav-link" data-scroll-target="#comparison-to-knn">Comparison to KNN</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#coding-section" id="toc-coding-section" class="nav-link" data-scroll-target="#coding-section">Coding Section</a>
  <ul class="collapse">
  <li><a href="#explore-data" id="toc-explore-data" class="nav-link" data-scroll-target="#explore-data">Explore Data</a></li>
  <li><a href="#testing-and-training-sets" id="toc-testing-and-training-sets" class="nav-link" data-scroll-target="#testing-and-training-sets">Testing and Training Sets</a></li>
  <li><a href="#knn-classification" id="toc-knn-classification" class="nav-link" data-scroll-target="#knn-classification">KNN Classification</a></li>
  <li><a href="#knn-for-regression" id="toc-knn-for-regression" class="nav-link" data-scroll-target="#knn-for-regression">KNN for Regression</a></li>
  <li><a href="#standard-linear-regression" id="toc-standard-linear-regression" class="nav-link" data-scroll-target="#standard-linear-regression">Standard Linear Regression</a></li>
  <li><a href="#stargazer-for-regression-output" id="toc-stargazer-for-regression-output" class="nav-link" data-scroll-target="#stargazer-for-regression-output">Stargazer for Regression Output</a></li>
  </ul></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content column-page-right" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Section 2 - KNN and Linear Regression</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Jacob Jameson </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<section id="notes" class="level1">
<h1>Notes</h1>
<p>Note that the material in these notes draws on past TF’s notes (Ibou Dieye, Laura Morris, Emily Mower, Amy Wickett), and the more thorough treatment of these topics in <em>Introduction to Statistical Learning</em> by Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani.</p>
<section id="important-machine-learning-concepts" class="level2">
<h2 class="anchored" data-anchor-id="important-machine-learning-concepts">Important Machine Learning Concepts</h2>
<section id="regression-vs-classification" class="level3">
<h3 class="anchored" data-anchor-id="regression-vs-classification">Regression vs Classification</h3>
<p>Prediction problems can be defined based on the characteristics of the outcome variable we want to predict.</p>
<ul>
<li><p><strong>Regression</strong> problems are those where the outcome is quantitative</p></li>
<li><p><strong>Classification</strong> problems are those where the outcome is qualitative / categorical</p></li>
</ul>
<p>Sometimes the same methods can be used for regression and classification problems, but many methods are useful for only one of the two problem types.</p>
</section>
<section id="bias-variance-trade-off" class="level3">
<h3 class="anchored" data-anchor-id="bias-variance-trade-off">Bias-Variance Trade-off</h3>
<p>The <strong>variance</strong> of a statistical learning method is the amount by which the prediction function would change if it was estimated on a different training set. A model that overfits has high variance, whereas a model that underfits has low variance.</p>
<p>To remember the difference between low variance and high variance models, I find it helpful to think of examples. Suppose your model was ``use the mean of the training data as the predicted value for all new data points.’’ The mean shouldn’t change much across training sets, so this has low variance. On the other hand, a model that picked up super complex patterns is likely to be picking up noise in addition to signal. The noise will vary by training set, so such a method would have high variance.</p>
<p>The <strong>bias</strong> of a statistical learning method is the error produced by representing a real world problem by a statistical learning method. Very flexible models (which are prone to overfitting) can capture complex patterns and so tend to have low bias. Very simple models (which are prone to underfitting) are limited in their ability to pick up patterns and so may have high bias.</p>
<p>The book uses the example of representing a non-linear function by a linear one to show that no matter how much data you have, a linear model will not do a great prediction job when the process generating the data is non-linear. Bias also applies to methods that might not fit your traditional concept of a statistical function. In the K-Nearest Neighbors section, we will discuss bias in that setting.</p>
<p>Often, we will talk about the <strong>bias-variance trade-off</strong>. In an ideal world, we would find a model that has low variance and low bias, because that would yield a good and consistent model. In practice, you usually have to allow bias to increase in order to decrease variance and vice versa. However, there are many models that will decrease one (bias or variance) significantly while only increasing the other a little.</p>
</section>
<section id="supervised-v.-unsupervised-learning" class="level3">
<h3 class="anchored" data-anchor-id="supervised-v.-unsupervised-learning">Supervised v. Unsupervised Learning</h3>
<p><strong>Supervised learning</strong> refers to problems where there is a known outcome. In these problems, you can train a model to take features and predict the known outcome.</p>
<p><strong>Unsupervised learning</strong> refers to problems where you are interested in uncovering patterns and do not have a target outcome in mind.</p>
<p>An example of supervised learning would be using students’ high school grades, class enrollments, and demographic variables to predict whether or not they attend college.</p>
<p>An example of unsupervised learning would be using the same grades, enrollment, and demographic features to identify ``types’’ of high school students. That is, students who look similar according to these features. Perhaps you are interested in this because you want to make classes that contain a mix of different types of students. Often, unsupervised learning is useful for creating features for supervised learning problems, but sometimes uncovering patterns is the final objective.</p>
</section>
<section id="measuring-model-performance" class="level3">
<h3 class="anchored" data-anchor-id="measuring-model-performance">Measuring Model Performance</h3>
<p>There are different functions you can use to measure model performance, and which function you choose depends on your data and your objective. These functions are called ``loss functions,’’ which is a somewhat intuitive name when you think about the fact that your machine learning algorithm is trying to minimize this function and thus minimize your loss.</p>
<p>To understand how and why loss functions depend on your data and objectives, examples can be helpful.</p>
<p>Consider first that you are trying to predict the future college majors of this year’s incoming freshmen (a classification problem). In this case, your prediction will either be right (you predict the major they end up choosing) or it will be wrong. Therefore, you might use accuracy (% correct) to measure model performance.</p>
<p>What if, though, you cared more about being wrong for some majors than others? For example, imagine that all biology majors are going to need personalized lab equipment in their junior year and that the lab equipment is really expensive if ordered last minute but a lot cheaper if ordered a year or more in advance? Then, you might want to give more weight to people who end up being biology majors so that your model does better for predicting biology majors than other majors.</p>
<p>Now consider that you are trying to predict home prices (a regression problem). You might measure your performance using mean-squared error (MSE), which is found by taking the difference between the predicted sale price for each home and the true sale price (the error), squaring it for each home, and then taking the mean of these squared errors. However, home prices are skewed (e.g.&nbsp;some homes are extremely expensive compared to most homes on the market). This means that a 5% error on a $3 million home is a lot bigger than a 5% error on a $100,000 home. When you square the errors (as you do when calculating MSE), the difference becomes enormous.</p>
<p>But since both errors are 5%, maybe you want to penalize them the same. One option is to use Mean Percentage Error (MPE), but this has the weird effect that if you over-predict one home by 5% and under-predict the other by 5%, your MPE is zero. Therefore, a popular option is to use the Mean Absolute Percentage Error (MAPE), which is the mean of the absolute values of the percentage errors and thus would be 5% in this example.</p>
<p>For many prediction problems in the policy sphere, we may not only care about accuracy of prediction but also about fairness or other objectives. The loss function is a place where we can explicitly tell the model to optimize for these concerns in addition to predictive performance.</p>
</section>
</section>
<section id="k-nearest-neighbors" class="level2">
<h2 class="anchored" data-anchor-id="k-nearest-neighbors">K-Nearest Neighbors</h2>
<section id="concept" class="level3">
<h3 class="anchored" data-anchor-id="concept">Concept</h3>
<p>The idea underlying K-Nearest Neighbors (KNN) is that we expect observations with similar features to have similar outcomes. KNN makes no other assumptions about functional form, so it is quite flexible.</p>
</section>
<section id="method" class="level3">
<h3 class="anchored" data-anchor-id="method">Method</h3>
<p>KNN can be used for either regression or classification, though it works slightly differently depending on what setting we are in. In the classification setting, the prediction is a majority vote of the observation’s <span class="math inline">\(K\)</span>-nearest neighbors. In the regression setting, the prediction is the average outcome of the observation’s <span class="math inline">\(K\)</span>-nearest neighbors.</p>
<p>For KNN, bias will be lower when <span class="math inline">\(K\)</span> is lower. Bias will increase quickly as k increases, with further away neighbors being included in the prediction.</p>
<p>The only choice we have to make when implementing KNN is the value of <span class="math inline">\(K\)</span> (e.g.&nbsp;how many neighbors should we use in our prediction?). A good way to find <span class="math inline">\(K\)</span> is through cross-validation, something we will cover a little later, but which broadly involves training the algorithm on one set of data and seeing how well it does on a different set.</p>
</section>
<section id="implementation-and-considerations" class="level3">
<h3 class="anchored" data-anchor-id="implementation-and-considerations">Implementation and Considerations</h3>
<p>A concern with KNN is whether you have good coverage of your feature space. Imagine that all of your training points were in one region of the feature space, but some of your test points are far away from this region. You will still use the <span class="math inline">\(K\)</span> nearest neighbors to predict the outcome for these far-away test points, but it might not work as well as if the points were close together. Therefore, when implementing KNN, it’s good to think about how similar the features in your test set will be to the features in your training set. If they differ systematically, that is a concern (as it would be for other ML methods as well).</p>
<p>Another important consideration is whether there is an imbalance in the frequency of one outcome compared to another. For example, suppose we are trying to classify points as <code>true'' or</code>false’’ and most points are <code>true.'' Even if the</code>false’’ outcomes are clustered together in the feature space, if we use a large enough value of <span class="math inline">\(K\)</span>, we will predict <code>true'' for these observations simply because there are many more</code>true’’ observations than ``false’’ observations. Therefore, we would do better to use a small value for <span class="math inline">\(K\)</span> in this setting.</p>
<p>Another consideration is whether proximity in each variable is equally important or if proximity in one variable is more important than proximity in another variable. KNN will normalize variables so that they are all on the same scale (same mean and variance) and then treat distance in all normalized variables the same. If you want to up-weight proximity for some variables and down-weight it for others, you can change the way each variable is normalized to accomplish this. Alternatively, you can include only those variables you think are important. When you have this type of uncertainty, there are more principled ways of selecting variables that will be discussed later in the course.</p>
</section>
<section id="extensions" class="level3">
<h3 class="anchored" data-anchor-id="extensions">Extensions</h3>
<p>You might think that neighbors that are really close should be weighted more than neighbors that are a bit further away. Many people agree, so there are methods to allow you to weight different observations differently. You might also think that you shouldn’t use just the <span class="math inline">\(K\)</span> nearest neighbors, but all the neighbors within a certain distance. Or maybe you think there’s information available in all observations, but there’s more information in closer neighbors. All of these adjustments fall under the umbrella of <strong>kernel regression</strong>. In fact, KNN is a special case of kernel regression. Broadly defined, kernel regression methods are a class of methods that generate predictions by taking weighted averages of observations. Because these methods (KNN included) do not specify a functional form, they are called ``non-parametric regression’’ methods.</p>
</section>
</section>
<section id="linear-regression" class="level2">
<h2 class="anchored" data-anchor-id="linear-regression">Linear Regression</h2>
<section id="concept-1" class="level3">
<h3 class="anchored" data-anchor-id="concept-1">Concept</h3>
<p>Linear regression is a parametric model that is additive and linear in the provided features. It is a classic technique used in many fields, and its widespread popularity greatly pre-dates the popularity of machine learning. Its general form is</p>
<p><span class="math display">\[\begin{equation}
    \hat{y} = \hat{\beta}X
\end{equation}\]</span></p>
<p>Where <span class="math inline">\(\hat{y}\)</span> is a vector of predicted <span class="math inline">\(y\)</span> values and <span class="math inline">\(X\)</span> is a matrix whose rows correspond to observations and whose columns correspond to features.</p>
<p>When there is only one feature on the right hand side, the model is called a <code>simple linear regression." When there are multiple features on the right hand side, the model is called</code>multiple linear regression.”</p>
<p>When used for inference, we are interested in <span class="math inline">\(\hat{\beta}\)</span>. However, when used for prediction, we are only interested in <span class="math inline">\(\hat{y}\)</span>, and we cannot say that the <span class="math inline">\(\hat{\beta}\)</span>s reflect any sort of causal relationship between the features and the outcome. For more information on how to test the significance of regression coefficients, please see Chapter 3 of <em>ISLR</em> for a reference on <span class="math inline">\(t\)</span>-tests (in the simple model) and <span class="math inline">\(F\)</span>-tests (in the multivariate model).</p>
</section>
<section id="method-1" class="level3">
<h3 class="anchored" data-anchor-id="method-1">Method</h3>
<p>To find the coefficients <span class="math inline">\(\hat{\beta}\)</span> in a linear regression, we find the value of <span class="math inline">\(\hat{\beta}\)</span> that minimizes the residual sum of squares (RSS) in the training data. The classic formula for <span class="math inline">\(\hat{\beta}\)</span> uses matrix algebra and is <span class="math display">\[\begin{equation}
    \hat{\beta} = (X^\prime X)^{-1}X^\prime y
\end{equation}\]</span> We will estimate <span class="math inline">\(\hat{\beta}\)</span> using statistical software.</p>
<p>It is worth noting that the traditional measure of fit for linear regression is <span class="math inline">\(R^2\)</span>, but <span class="math inline">\(R^2\)</span> mechanically increases with the inclusion of additional features. Therefore, in the prediction setting, the <span class="math inline">\(R^2\)</span> on the training data is less important than the mean squared error (MSE) on the test data.</p>
</section>
<section id="implementation-and-considerations-1" class="level3">
<h3 class="anchored" data-anchor-id="implementation-and-considerations-1">Implementation and Considerations</h3>
<p>There are a few things to watch out for as far as the features that you feed into a linear regression.</p>
<ul>
<li><p>There must be fewer features than observations. Later in the semester, we will cover penalized regression methods that do variable selection to yield estimable linear models, even when the number of available features exceeds the number of observations. Common penalized regression methods are lasso and ridge regression.</p></li>
<li><p>You can use quantitative or qualitative features for the <span class="math inline">\(X\)</span>s. When using qualitative features, generate indicator variables for all but one category. The omitted category will serve as the ``baseline,’’ meaning that the coefficients on the included categories can be thought of as the differential effect of being in that category compared to the baseline (omitted) one.</p></li>
<li><p>The reason you omit one category when making indicator variables is to avoid linear dependence. If all categories were represented, the indicator columns would all sum to 1, which would mean they were linearly dependent. More generally, you cannot have collinearity or multi-collinearity, which means you cannot have features that are (close to) perfectly correlated.</p></li>
<li><p>You can interact two features (e.g.&nbsp;create a feature that is the product of two other features), and such interactions are valid on categorical and continuous features. However, when you include an interaction, you should also include each of the features on their own as well. Interactions have intuitive appeal if you think there are synergies between two features in terms of their effect on <span class="math inline">\(y\)</span>.</p></li>
<li><p>You can exponentiate features and include the exponentiated features in your model. The resulting model is sometimes called polynomial regression and is appropriate when there appears to be a non-linear relationship between a feature and the outcome.</p></li>
<li><p>Check for influential points – those that are both <em>outliers</em> (they have an unusual or extreme <span class="math inline">\(y\)</span> value) and <em>high leverage</em> (they have an unusual or extreme <span class="math inline">\(x\)</span>), as these points can greatly influence the model fit. You may want to exclude them or at least check your model’s sensitivity to including them versus excluding them.</p></li>
</ul>
<p>If you are interested in inference (e.g.&nbsp;looking at the <span class="math inline">\(\hat{\beta}\)</span>s to understand a causal relationship), it is important to be aware of Omitted Variables Bias (OVB). OVB occurs when you have two correlated features that each have an effect on <span class="math inline">\(y\)</span> but only one is included in the regression. In that case, the coefficient on the included feature is biased, because it is partially picking up the true effect of the feature on the outcome and is also partially picking up the effect of the omitted feature on the outcome (since the omitted feature is correlated with the included feature).</p>
<p>As an example of OVB, suppose <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are positively (but not perfectly) correlated. If they are also both positively correlated with <span class="math inline">\(y\)</span>, then when <span class="math inline">\(X_2\)</span> is omitted from the regression, the coefficient on <span class="math inline">\(X_1\)</span> will be higher than when both <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are included. This is because the coefficient on <span class="math inline">\(X_1\)</span> will now pick up both the effect of <span class="math inline">\(X_1\)</span> on <span class="math inline">\(y\)</span> and part of the effect of <span class="math inline">\(X_2\)</span> on <span class="math inline">\(y\)</span> (since <span class="math inline">\(X_1\)</span> is a proxy for <span class="math inline">\(X_2\)</span> because the two features are positively correlated).</p>
<p>When implementing linear regression, you should also take a look at your residuals and make sure there are no red flags:</p>
<ul>
<li><p>When you plot residuals, they should appear randomly scattered. Any non-linearity or patterns in the residuals suggest your model is not appropriate.</p></li>
<li><p>Linear regression assumes residuals are uncorrelated. Evidence of correlated residuals indicates a problem with your model or your data that should be investigated.</p></li>
<li><p>Residuals should have constant variance. If you plot your residuals and their variance seems to be a function of <span class="math inline">\(x\)</span>, then the errors are <em>heteroskedastic</em> (a fancy word for ``a function of <span class="math inline">\(x\)</span>’’). In this case, traditional statistical measures of significance are invalid, but other valid methods are available.</p></li>
</ul>
</section>
<section id="comparison-to-knn" class="level3">
<h3 class="anchored" data-anchor-id="comparison-to-knn">Comparison to KNN</h3>
<p>The main difference of note between linear regression and KNN is that linear regression is a parametric model whereas KNN is a non-parametric model. There are a few general differences between parametric and non-parametric models that are worth noting</p>
<ul>
<li><p>Non-parametric models are more flexible whereas parametric models impose stronger assumptions</p></li>
<li><p>When there is a small number of observations per feature, parametric models tend to outperform non-parametric models</p></li>
</ul>
<p>In addition to the general differences between parametric and non-parametric models, a key difference between KNN and linear regression is that linear regression is quite simple to fit. In fact, it only requires estimation of a few <span class="math inline">\(\beta\)</span>s, whereas KNN is much more computationally intensive. Because of this simplicity, linear regression is also more interpretable than KNN.</p>
</section>
</section>
</section>
<section id="coding-section" class="level1">
<h1>Coding Section</h1>
<p>There are lots of great datasets available as part of R packages. Page 14 of Introduction to Statistical Learning with Applications in R Table 1.1 lays out 15 data sets available from R packages. We will use the College dataset from the ISLR package. The first time you ever use a package, you need to install it. Then, every time you want to use the package, you use <code>library(package_name)</code>. We will use the college data. Note that details on this data are available online: https://cran.r-project.org/web/packages/ISLR/ISLR.pdf Page 5. You can also get the same information in R by typing: help(“College”) or ?College.</p>
<section id="explore-data" class="level2">
<h2 class="anchored" data-anchor-id="explore-data">Explore Data</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ISLR)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(College)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>college_data  <span class="ot">&lt;-</span> College</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s learn about our data. To get the names of the columns in the dataframe, we can use the function <code>colnames()</code></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(college_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] "Private"     "Apps"        "Accept"      "Enroll"      "Top10perc"  
 [6] "Top25perc"   "F.Undergrad" "P.Undergrad" "Outstate"    "Room.Board" 
[11] "Books"       "Personal"    "PhD"         "Terminal"    "S.F.Ratio"  
[16] "perc.alumni" "Expend"      "Grad.Rate"  </code></pre>
</div>
</div>
<p>To find out how many rows and columns are in the dataset, use <code>dim()</code> Recall that this gives us Rows followed by Columns</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(college_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 777  18</code></pre>
</div>
</div>
<p>You can also look in the “environment” tab, press the blue arrow next to college_data and it will drop down showing the column names with their types and first few values. For college, all columns except the first are numeric. The first column is a factor column, which means it’s categorical. To get a better sense of the data, let’s look at it:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">View</span>(college_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Suppose we are interested in predicting whether a college is private or public based on available covariates, like Number accepted, enrolled, etc. Additionally, let’s suppose you don’t want certain variables included in your dataset. You can drop these functions using -c(). For example, let’s suppose you don’t want the Apps or Student to Faculty Ratio included in your dataset.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>college_data <span class="ot">&lt;-</span> college_data[, <span class="sc">-</span><span class="fu">c</span>(<span class="dv">15</span>, <span class="dv">2</span>)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Be careful when you are dropping multiple columns. You need to put the numbers in reverse order (from highest to lowest). This is because if you drop the second column first, then the 15th column becomes the the 14th column.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>college_data <span class="ot">&lt;-</span> College</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>college_data <span class="ot">&lt;-</span> college_data[, <span class="sc">-</span><span class="fu">c</span>(<span class="dv">2</span>)]</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>college_data <span class="ot">&lt;-</span> college_data[, <span class="sc">-</span><span class="fu">c</span>(<span class="dv">15</span>)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>A less manual way of dropping columns is to use R to first use R to find the corresponding indices in the data columns. Go back to the original college data</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>college_data <span class="ot">&lt;-</span> College</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Find the indices (i.e.&nbsp;column positions) of the columns to drop</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>to_drop <span class="ot">&lt;-</span> <span class="fu">which</span>(<span class="fu">names</span>(college_data) <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">"Apps"</span>, <span class="st">"S.F.Ratio"</span>))</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(to_drop)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1]  2 15</code></pre>
</div>
</div>
<p>Reverse the indices as suggested above</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>to_drop <span class="ot">&lt;-</span> <span class="fu">rev</span>(to_drop)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(to_drop)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 15  2</code></pre>
</div>
</div>
<p>Now use the object you have defined to drop the columns</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>college_data <span class="ot">&lt;-</span> college_data[, <span class="sc">-</span><span class="fu">c</span>(to_drop)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Also sometimes we have factor variables that we want to convert to numeric variables. To check variable types, you can use the “str” function</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(college_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>'data.frame':   777 obs. of  16 variables:
 $ Private    : Factor w/ 2 levels "No","Yes": 2 2 2 2 2 2 2 2 2 2 ...
 $ Accept     : num  1232 1924 1097 349 146 ...
 $ Enroll     : num  721 512 336 137 55 158 103 489 227 172 ...
 $ Top10perc  : num  23 16 22 60 16 38 17 37 30 21 ...
 $ Top25perc  : num  52 29 50 89 44 62 45 68 63 44 ...
 $ F.Undergrad: num  2885 2683 1036 510 249 ...
 $ P.Undergrad: num  537 1227 99 63 869 ...
 $ Outstate   : num  7440 12280 11250 12960 7560 ...
 $ Room.Board : num  3300 6450 3750 5450 4120 ...
 $ Books      : num  450 750 400 450 800 500 500 450 300 660 ...
 $ Personal   : num  2200 1500 1165 875 1500 ...
 $ PhD        : num  70 29 53 92 76 67 90 89 79 40 ...
 $ Terminal   : num  78 30 66 97 72 73 93 100 84 41 ...
 $ perc.alumni: num  12 16 30 37 2 11 26 37 23 15 ...
 $ Expend     : num  7041 10527 8735 19016 10922 ...
 $ Grad.Rate  : num  60 56 54 59 15 55 63 73 80 52 ...</code></pre>
</div>
</div>
<p>You can see that the Private variable is a factor. We can convert it to a numeric variable using the “as.numeric” function. I like my binary variables in R to be 0/1. In R, most factors automatically convert to a binary 1/2 format. I usually prefer a binary 0/1 format. To transform, I subtract 1.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>college_data<span class="sc">$</span>Private <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(college_data<span class="sc">$</span>Private) <span class="sc">-</span> <span class="dv">1</span> </span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(college_data<span class="sc">$</span>Private)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.0000  0.0000  1.0000  0.7272  1.0000  1.0000 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(College<span class="sc">$</span>Private)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> No Yes 
212 565 </code></pre>
</div>
</div>
<p>Let’s get back our original sample</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>college_data <span class="ot">&lt;-</span> College</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="testing-and-training-sets" class="level2">
<h2 class="anchored" data-anchor-id="testing-and-training-sets">Testing and Training Sets</h2>
<p>In order to make this interesting, let’s split our data into a training set and a test set. To do this, we will use <code>set.seed()</code>, which will allow us to draw the same pseudorandom numbers the next time we run this code, and we will use the <code>sample()</code> function.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">222</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The <code>sample()</code> function takes two arguments: The first is a vector of numbers from which to draw a random sample. The second is the number of random numbers to draw. The default is to sample without replacement, but you can sample with replacement by adding “<code>, replace = TRUE</code>” inside the function. Now, let’s generate a list of indices from the original dataset that will be designated part of the test set using <code>sample()</code></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>test_ids <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>(<span class="fu">nrow</span>(college_data)), <span class="fu">round</span>(<span class="fl">0.2</span> <span class="sc">*</span> <span class="fu">nrow</span>(college_data)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To identify the training_ids, we want all of the numbers from 1:nrow(college_data) that aren’t test IDs. Recall that <code>which()</code> returns the indices for which the statement inside the parentheses is true. <code>which(!())</code> returns the indices for which the statement inside the parentheses is false. The “!” means “not”. Also, if you wanted to know which values of vector A were in vector B, you can use <code>which(A %in% B)</code>. So if you want to know which values of vector A are NOT in vector B, you use <code>which(!(A %in B))</code>, so that’s what we will do – vector A is the vector of all integers between 1 and the number of rows in our data. vector B is the vector of test IDs</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>training_ids <span class="ot">&lt;-</span> <span class="fu">which</span>(<span class="sc">!</span>(<span class="dv">1</span><span class="sc">:</span>(<span class="fu">nrow</span>(college_data)) <span class="sc">%in%</span> test_ids))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can use these indices to define our test and training sets by putting those vectors in the row position inside square brackets.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>test_data <span class="ot">&lt;-</span> college_data[test_ids,]</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>training_data <span class="ot">&lt;-</span> college_data[training_ids,]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="knn-classification" class="level2">
<h2 class="anchored" data-anchor-id="knn-classification">KNN Classification</h2>
<p>Let’s develop a KNN model to try to predict whether it’s a private college using all available features.</p>
<p>To use KNN for classification, we need to install and load the library “class”</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(class)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>knn() is the function we will use to run the KNN model. It takes four arguments:</p>
<ul>
<li>train = training data features (no outcome)</li>
<li>test = test data features (no outcome)</li>
<li>cl = training data outcome (class each observation belongs to)</li>
<li>k = number of nearest neighbors to use</li>
</ul>
<p>For two-class classification problems, k should be odd (avoids tied votes). Let’s run the model with 1 NN and 9 NNs. To exclude a column, use -# in the column position insider square brackets. (e.g.&nbsp;df[, -2] excludes the second column of dataframe df)</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>knn_model1 <span class="ot">&lt;-</span> <span class="fu">knn</span>(<span class="at">train =</span> training_data[, <span class="sc">-</span><span class="dv">1</span>],</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>                  <span class="at">test =</span> test_data[, <span class="sc">-</span><span class="dv">1</span>],</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">cl =</span> training_data<span class="sc">$</span>Private,</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>                  <span class="at">k =</span> <span class="dv">1</span>)</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>knn_model9 <span class="ot">&lt;-</span> <span class="fu">knn</span>(<span class="at">train =</span> training_data[, <span class="sc">-</span><span class="dv">1</span>],</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>                  <span class="at">test =</span> test_data[, <span class="sc">-</span><span class="dv">1</span>],</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>                  <span class="at">cl =</span> training_data<span class="sc">$</span>Private,</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>                  <span class="at">k =</span> <span class="dv">9</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We are trying to predict Private Yes/No.&nbsp;<code>knn()</code> output predicted values for our test data, so we can compare actual v. predicted values. “prediction == actual” gives a vector with the same number of elements as there are observations in the test set. Each element will either be TRUE (the prediction was correct) or FALSE (the prediction was wrong). Applying which() to this vector will yield the index numbers for all the elements equal to TRUE. Applying length() to that vector tells us how many are TRUE (e.g.&nbsp;for how many observations prediction == actual). We can then divide by the number of observations in the test data to obtain the accuracy rate</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>accuracy1  <span class="ot">&lt;-</span> <span class="fu">length</span>(<span class="fu">which</span>(knn_model1 <span class="sc">==</span> test_data<span class="sc">$</span>Private)) <span class="sc">/</span> <span class="fu">nrow</span>(test_data)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>accuracy9 <span class="ot">&lt;-</span> <span class="fu">length</span>(<span class="fu">which</span>(knn_model9 <span class="sc">==</span> test_data<span class="sc">$</span>Private)) <span class="sc">/</span> <span class="fu">nrow</span>(test_data)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(accuracy1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9096774</code></pre>
</div>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(accuracy9)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9225806</code></pre>
</div>
</div>
<p>Let’s visualize what is happening in a KNN classification model. We will use the <code>ggplot2</code> package to create a scatterplot of the training data, and then overlay the test data on top of it. We will color the points by whether the school is private or not.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> training_data, </span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>       <span class="fu">aes</span>(<span class="at">x =</span> Outstate, <span class="at">y =</span> F.Undergrad, </span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>           <span class="at">color =</span> <span class="fu">as.factor</span>(Private))) <span class="sc">+</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> test_data, <span class="fu">aes</span>(<span class="at">x =</span> Outstate, <span class="at">y =</span> F.Undergrad), </span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>             <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"red"</span>, <span class="st">"blue"</span>)) <span class="sc">+</span></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">guides</span>(<span class="at">color =</span> <span class="fu">guide_legend</span>(<span class="at">title =</span> <span class="st">"Private"</span>)) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="section2_files/figure-html/unnamed-chunk-21-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>This seems like excellent predictive performance. However, it’s good to think about the distribution of the data. As an extreme example, if all schools in the data were private, we would expect 100% prediction accuracy regardless of our model. Let’s see how well we do if our prediction is all schools are Private. Start by calculating the proportion of private schools</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">length</span>(<span class="fu">which</span>(test_data<span class="sc">$</span>Private <span class="sc">==</span> <span class="st">"Yes"</span>)) <span class="sc">/</span> <span class="fu">nrow</span>(test_data))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.716129</code></pre>
</div>
</div>
<p>We can also check our accuracy on Private schools v. Public schools. To do this, we need to figure out which schools are private in the test data. Specifically, get the indices for the private schools</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>private_schools <span class="ot">&lt;-</span> <span class="fu">which</span>(test_data<span class="sc">$</span>Private <span class="sc">==</span> <span class="st">"Yes"</span>)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>public_schools <span class="ot">&lt;-</span> <span class="fu">which</span>(test_data<span class="sc">$</span>Private <span class="sc">==</span> <span class="st">"No"</span>)</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(private_schools)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  [1]   1   2   3   8  11  12  13  14  15  16  18  19  20  21  22  23  24  27
 [19]  28  29  30  31  32  33  34  35  37  38  39  41  42  43  44  45  47  48
 [37]  49  50  51  52  53  55  56  57  58  60  61  62  63  64  65  66  68  69
 [55]  76  77  78  80  81  82  84  85  86  90  91  92  93  94  96  97  99 100
 [73] 101 102 104 106 107 108 110 112 113 116 119 120 121 122 123 125 127 128
 [91] 129 130 133 134 135 136 137 138 139 140 142 145 146 147 148 149 151 152
[109] 153 154 155</code></pre>
</div>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(public_schools)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1]   4   5   6   7   9  10  17  25  26  36  40  46  54  59  67  70  71  72  73
[20]  74  75  79  83  87  88  89  95  98 103 105 109 111 114 115 117 118 124 126
[39] 131 132 141 143 144 150</code></pre>
</div>
</div>
<p>To calculate the prediction accuracy for private schools, we need to know how many (true not predicted) private schools are in the test data. Likewise, we need to know how many public schools are in the test data.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>num_private_schools <span class="ot">&lt;-</span> <span class="fu">length</span>(private_schools)</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>num_public_schools <span class="ot">&lt;-</span> <span class="fu">length</span>(public_schools)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now we will calculate the prediction accuracy separately for private and public schools.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>private_accuracy1 <span class="ot">&lt;-</span> <span class="fu">length</span>(</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">which</span>(knn_model1[private_schools] <span class="sc">==</span> test_data<span class="sc">$</span>Private[private_schools])) <span class="sc">/</span></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>  num_private_schools</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>private_accuracy9 <span class="ot">&lt;-</span> <span class="fu">length</span>(</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">which</span>(knn_model9[private_schools] <span class="sc">==</span> test_data<span class="sc">$</span>Private[private_schools])) <span class="sc">/</span></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>  num_private_schools</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now we will calculate the prediction accuracy separately for private and public schools.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Private schools (% correctly predicted):</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>private_accuracy1 <span class="ot">&lt;-</span> <span class="fu">length</span>(</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">which</span>(knn_model1[private_schools] <span class="sc">==</span> test_data<span class="sc">$</span>Private[private_schools])) <span class="sc">/</span></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>  num_private_schools</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>private_accuracy9 <span class="ot">&lt;-</span> <span class="fu">length</span>(</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">which</span>(knn_model9[private_schools] <span class="sc">==</span> test_data<span class="sc">$</span>Private[private_schools])) <span class="sc">/</span></span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>  num_private_schools</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Public schools (% correctly predicted): </span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>public_accuracy1 <span class="ot">&lt;-</span> <span class="fu">length</span>(</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">which</span>(knn_model1[public_schools] <span class="sc">==</span> test_data<span class="sc">$</span>Private[public_schools])) <span class="sc">/</span></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>  num_public_schools</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>public_accuracy9 <span class="ot">&lt;-</span> <span class="fu">length</span>(</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">which</span>(knn_model9[public_schools] <span class="sc">==</span> test_data<span class="sc">$</span>Private[public_schools])) <span class="sc">/</span></span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>  num_public_schools</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s see how it did on different school types:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(private_accuracy1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9459459</code></pre>
</div>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(public_accuracy1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.8181818</code></pre>
</div>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(private_accuracy9)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.972973</code></pre>
</div>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(public_accuracy9)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.7954545</code></pre>
</div>
</div>
<p>Therefore, we did better on private schools than public schools because our prediction accuracy was higher on private schools. Thinking about differential performance by label is related to fairness of machine learning algorithms. For an interesting discussion on ML fairness and different ways to define fairness, see the following academic paper:</p>
<pre><code>Jon Kleinberg, Sendhil Mullainathan, and Manish Raghavan. 
Inherent Trade-Offs in the Fair
Determination of Risk Scores, November 2016</code></pre>
</section>
<section id="knn-for-regression" class="level2">
<h2 class="anchored" data-anchor-id="knn-for-regression">KNN for Regression</h2>
<p>Suppose we wanted to predict how many students would enroll given the other features available in the data. In that case, the classification function we used above will not work. We will need a KNN function designed for regression problems. This function is <code>knn.reg()</code> in the <code>FNN</code> package, so we should install then read in the FNN package.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="co">#install.packages("FNN")</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(FNN)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>knn.reg() takes four arguments: - training data with only features (no outcome) - test data with only features (no outcome) - training outcomes - k = number of neighbors</p>
<p>Enrollment is the fourth column, so we will exclude that from the features. Because public / private is a factor, we either need to convert it to a numeric variable or exclude it. We will exclude it for now. Note that you can scale your features using <code>scale()</code>. Deciding to scale your features or not is problem dependent. We will not scale here. If you’re not sure whether or not to scale, you can always try it both ways and see how the performance changes.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>knn_reg1 <span class="ot">&lt;-</span> <span class="fu">knn.reg</span>(training_data[, <span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">4</span>)],</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>                    test_data[, <span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">4</span>)],</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>                    training_data<span class="sc">$</span>Enroll,</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>                    <span class="at">k =</span> <span class="dv">1</span>)</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a>knn_reg5 <span class="ot">&lt;-</span> <span class="fu">knn.reg</span>(training_data[, <span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">4</span>)],</span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a>                    test_data[,<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">4</span>)],</span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a>                    training_data<span class="sc">$</span>Enroll,</span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a>                    <span class="at">k =</span> <span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>knn_reg1<span class="sc">$</span>pred</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  [1] 1492  185  302 2529 1464 1408 1930  177 1547 1652  278  363  452  572  176
 [16]  276 1973  323  137  197  200  489  456  108 1025  208  172 1194 1685  419
 [31]  156  361  432  502  659 1561  220  157  210 5873  144  753 1499  294  452
 [46]  951  375  306  437  217  380  543  695 1561  383  481  146  910  443  456
 [61]  185  235  151  228  363 1492 2367  350  452 1030  819  326 2678  265 1697
 [76]  465  337  575 1071  176  514  575  510  366  579  210  361 2408 1016  352
 [91]   91  276  806  314 1515  215  276 2133  227  306 1191   96 2408  688 1436
[106]  177  298  691  376  500 4893  363  484  560  985  246  695 2408  691  504
[121]  157  167   55 1036 1368 1515  177  244  456  306 2940  363  361  557  910
[136]  125  167  137  298  248 3147  266 6180 1627  167  334  300  354 3087  217
[151]  383  776  328  477  458</code></pre>
</div>
</div>
<p>MSE is an appropriate loss function for regression whereas accuracy is only relevant for classification</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>mse_knn1 <span class="ot">&lt;-</span> <span class="fu">mean</span>((knn_reg1<span class="sc">$</span>pred <span class="sc">-</span> test_data<span class="sc">$</span>Enroll)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>mse_knn5 <span class="ot">&lt;-</span> <span class="fu">mean</span>((knn_reg5<span class="sc">$</span>pred <span class="sc">-</span> test_data<span class="sc">$</span>Enroll)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(mse_knn1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 124500.9</code></pre>
</div>
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(mse_knn5)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 73296.56</code></pre>
</div>
</div>
</section>
<section id="standard-linear-regression" class="level2">
<h2 class="anchored" data-anchor-id="standard-linear-regression">Standard Linear Regression</h2>
<p>We will now do linear regression. To run a linear regression in R, we use the function <code>lm()</code>, which stands for linear model. <code>lm()</code> takes two main arguments. The first is the formula, which should be of the form Dependent Variable ~ Feature1 + Feature2 + … The second is the training data – including both features and the outcome. Note that “<code>~.</code>” means regress this variable on all other variables</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>enroll_reg <span class="ot">&lt;-</span> <span class="fu">lm</span>(Enroll <span class="sc">~</span> ., training_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(stargazer)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>
Please cite as: </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code> Hlavac, Marek (2022). stargazer: Well-Formatted Regression and Summary Statistics Tables.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code> R package version 5.2.3. https://CRAN.R-project.org/package=stargazer </code></pre>
</div>
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="fu">stargazer</span>(enroll_reg, <span class="at">type =</span> <span class="st">"text"</span>, <span class="at">single.row =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
===============================================
                        Dependent variable:    
                    ---------------------------
                              Enroll           
-----------------------------------------------
PrivateYes                7.807 (30.036)       
Apps                     -0.028*** (0.008)     
Accept                   0.147*** (0.015)      
Top10perc                4.016*** (1.283)      
Top25perc                -2.269** (0.997)      
F.Undergrad              0.144*** (0.004)      
P.Undergrad               -0.012* (0.007)      
Outstate                  -0.003 (0.004)       
Room.Board               -0.024** (0.011)      
Books                     -0.027 (0.049)       
Personal                   0.008 (0.014)       
PhD                       -0.431 (1.002)       
Terminal                  -0.540 (1.094)       
S.F.Ratio                 -0.253 (2.843)       
perc.alumni              2.319*** (0.879)      
Expend                     0.003 (0.003)       
Grad.Rate                  0.136 (0.648)       
Constant                187.938** (89.615)     
-----------------------------------------------
Observations                    622            
R2                             0.956           
Adjusted R2                    0.955           
Residual Std. Error     202.349 (df = 604)     
F Statistic          768.822*** (df = 17; 604) 
===============================================
Note:               *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
</div>
</div>
<p>lm() returns a list, which includes among other things coefficients, residuals, and fitted values for the training data. You can look at the elements in RStudio by using the blue arrow next to enroll_reg in the environment tab. In order to call one element of a list, you can use $</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>enroll_reg<span class="sc">$</span>coefficients</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  (Intercept)    PrivateYes          Apps        Accept     Top10perc 
187.938169332   7.806939217  -0.027759639   0.146504112   4.016271367 
    Top25perc   F.Undergrad   P.Undergrad      Outstate    Room.Board 
 -2.268522370   0.144249348  -0.011850547  -0.003105257  -0.024152785 
        Books      Personal           PhD      Terminal     S.F.Ratio 
 -0.027184975   0.008447046  -0.431202139  -0.539993156  -0.253400149 
  perc.alumni        Expend     Grad.Rate 
  2.319201329   0.003018132   0.135713594 </code></pre>
</div>
</div>
<p>In order to see a more traditional regression output, use <code>summary()</code></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(enroll_reg)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = Enroll ~ ., data = training_data)

Residuals:
     Min       1Q   Median       3Q      Max 
-1284.27   -60.18    -8.62    51.46  1544.82 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 187.938169  89.614941   2.097 0.036393 *  
PrivateYes    7.806939  30.036405   0.260 0.795017    
Apps         -0.027760   0.008149  -3.406 0.000702 ***
Accept        0.146504   0.014710   9.959  &lt; 2e-16 ***
Top10perc     4.016271   1.283269   3.130 0.001834 ** 
Top25perc    -2.268522   0.996912  -2.276 0.023222 *  
F.Undergrad   0.144249   0.004298  33.560  &lt; 2e-16 ***
P.Undergrad  -0.011851   0.006753  -1.755 0.079809 .  
Outstate     -0.003105   0.004185  -0.742 0.458327    
Room.Board   -0.024153   0.010712  -2.255 0.024500 *  
Books        -0.027185   0.049391  -0.550 0.582244    
Personal      0.008447   0.013655   0.619 0.536410    
PhD          -0.431202   1.002234  -0.430 0.667174    
Terminal     -0.539993   1.094362  -0.493 0.621887    
S.F.Ratio    -0.253400   2.843330  -0.089 0.929015    
perc.alumni   2.319201   0.879334   2.637 0.008568 ** 
Expend        0.003018   0.002639   1.144 0.253219    
Grad.Rate     0.135714   0.647956   0.209 0.834168    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 202.3 on 604 degrees of freedom
Multiple R-squared:  0.9558,    Adjusted R-squared:  0.9546 
F-statistic: 768.8 on 17 and 604 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>If you want to use the coefficients from enroll_reg to predict enrollment values in the test data, you can use the function <code>predict()</code>. The first argument is the lm object (the whole thing – not just the coefficients) and the second argument is the test data frame without the outcome column</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>predicted_enroll <span class="ot">&lt;-</span> <span class="fu">predict</span>(enroll_reg, test_data[, <span class="sc">-</span><span class="dv">4</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s see how well we did in terms of MSE</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>MSE_lm_enroll <span class="ot">&lt;-</span> <span class="fu">mean</span>((predicted_enroll <span class="sc">-</span> test_data<span class="sc">$</span>Enroll)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(MSE_lm_enroll)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 39312.19</code></pre>
</div>
</div>
<p>We can see how this compared to our training MSE</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">mean</span>((enroll_reg<span class="sc">$</span>residuals)<span class="sc">^</span><span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 39760.39</code></pre>
</div>
</div>
<p>Training MSE as % of Test MSE:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">mean</span>((enroll_reg<span class="sc">$</span>residuals)<span class="sc">^</span><span class="dv">2</span>) <span class="sc">/</span> MSE_lm_enroll)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.011401</code></pre>
</div>
</div>
<p>We know that the coefficients might change if we exclude some variables. Let’s pretend we only had Apps and Accept (columns 2 and 3) as features</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a>small_enroll_reg  <span class="ot">&lt;-</span> <span class="fu">lm</span>(Enroll <span class="sc">~</span> Apps <span class="sc">+</span> Accept, training_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can compare coefficients from the small regression and the full regression. If the coefficients in the small regression are different from the coefficients in the full regression, then the small regression suffers from Omitted Variables Bias (OVB).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>small_enroll_reg<span class="sc">$</span>coefficients</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)        Apps      Accept 
86.88115150 -0.05243254  0.42420181 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a>enroll_reg<span class="sc">$</span>coefficients</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  (Intercept)    PrivateYes          Apps        Accept     Top10perc 
187.938169332   7.806939217  -0.027759639   0.146504112   4.016271367 
    Top25perc   F.Undergrad   P.Undergrad      Outstate    Room.Board 
 -2.268522370   0.144249348  -0.011850547  -0.003105257  -0.024152785 
        Books      Personal           PhD      Terminal     S.F.Ratio 
 -0.027184975   0.008447046  -0.431202139  -0.539993156  -0.253400149 
  perc.alumni        Expend     Grad.Rate 
  2.319201329   0.003018132   0.135713594 </code></pre>
</div>
</div>
</section>
<section id="stargazer-for-regression-output" class="level2">
<h2 class="anchored" data-anchor-id="stargazer-for-regression-output">Stargazer for Regression Output</h2>
<p>If you want to compare the coefficients from different regressions, you can use the <code>stargazer</code> package. This package is not installed by default, so you will need to install it.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="co">#install.packages("stargazer")</span></span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(stargazer)</span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a><span class="fu">stargazer</span>(small_enroll_reg, enroll_reg, </span>
<span id="cb83-5"><a href="#cb83-5" aria-hidden="true" tabindex="-1"></a>          <span class="at">type =</span> <span class="st">"text"</span>, <span class="at">column.labels =</span> <span class="fu">c</span>(<span class="st">"Small Model"</span>, <span class="st">"Full Model"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
========================================================================
                                    Dependent variable:                 
                    ----------------------------------------------------
                                           Enroll                       
                           Small Model                Full Model        
                               (1)                        (2)           
------------------------------------------------------------------------
PrivateYes                                               7.807          
                                                       (30.036)         
                                                                        
Apps                        -0.052***                  -0.028***        
                             (0.013)                    (0.008)         
                                                                        
Accept                       0.424***                  0.147***         
                             (0.021)                    (0.015)         
                                                                        
Top10perc                                              4.016***         
                                                        (1.283)         
                                                                        
Top25perc                                              -2.269**         
                                                        (0.997)         
                                                                        
F.Undergrad                                            0.144***         
                                                        (0.004)         
                                                                        
P.Undergrad                                             -0.012*         
                                                        (0.007)         
                                                                        
Outstate                                                -0.003          
                                                        (0.004)         
                                                                        
Room.Board                                             -0.024**         
                                                        (0.011)         
                                                                        
Books                                                   -0.027          
                                                        (0.049)         
                                                                        
Personal                                                 0.008          
                                                        (0.014)         
                                                                        
PhD                                                     -0.431          
                                                        (1.002)         
                                                                        
Terminal                                                -0.540          
                                                        (1.094)         
                                                                        
S.F.Ratio                                               -0.253          
                                                        (2.843)         
                                                                        
perc.alumni                                            2.319***         
                                                        (0.879)         
                                                                        
Expend                                                   0.003          
                                                        (0.003)         
                                                                        
Grad.Rate                                                0.136          
                                                        (0.648)         
                                                                        
Constant                    86.881***                  187.938**        
                             (20.984)                  (89.615)         
                                                                        
------------------------------------------------------------------------
Observations                   622                        622           
R2                            0.820                      0.956          
Adjusted R2                   0.819                      0.955          
Residual Std. Error     403.989 (df = 619)        202.349 (df = 604)    
F Statistic         1,405.761*** (df = 2; 619) 768.822*** (df = 17; 604)
========================================================================
Note:                                        *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
</div>
</div>
<p>You can also also use stargazer to get the latex code for a table. This is useful if you want to include the table in a paper or a presentation.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="fu">stargazer</span>(small_enroll_reg, enroll_reg, </span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>          <span class="at">type =</span> <span class="st">"latex"</span>, </span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>          <span class="at">column.labels =</span> <span class="fu">c</span>(<span class="st">"Small Model"</span>, <span class="st">"Full Model"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>

<table style="text-align:center">
<tbody><tr>
<td colspan="3" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td colspan="2">
<em>Dependent variable:</em>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="2" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td colspan="2">
Enroll
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
Small Model
</td>
<td>
Full Model
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
(1)
</td>
<td>
(2)
</td>
</tr>
<tr>
<td colspan="3" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
PrivateYes
</td>
<td>
</td>
<td>
7.807
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
(30.036)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
Apps
</td>
<td>
-0.052<sup>***</sup>
</td>
<td>
-0.028<sup>***</sup>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
(0.013)
</td>
<td>
(0.008)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
Accept
</td>
<td>
0.424<sup>***</sup>
</td>
<td>
0.147<sup>***</sup>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
(0.021)
</td>
<td>
(0.015)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
Top10perc
</td>
<td>
</td>
<td>
4.016<sup>***</sup>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
(1.283)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
Top25perc
</td>
<td>
</td>
<td>
-2.269<sup>**</sup>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
(0.997)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
F.Undergrad
</td>
<td>
</td>
<td>
0.144<sup>***</sup>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
(0.004)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
P.Undergrad
</td>
<td>
</td>
<td>
-0.012<sup>*</sup>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
(0.007)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
Outstate
</td>
<td>
</td>
<td>
-0.003
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
(0.004)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
Room.Board
</td>
<td>
</td>
<td>
-0.024<sup>**</sup>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
(0.011)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
Books
</td>
<td>
</td>
<td>
-0.027
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
(0.049)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
Personal
</td>
<td>
</td>
<td>
0.008
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
(0.014)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
PhD
</td>
<td>
</td>
<td>
-0.431
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
(1.002)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
Terminal
</td>
<td>
</td>
<td>
-0.540
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
(1.094)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
S.F.Ratio
</td>
<td>
</td>
<td>
-0.253
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
(2.843)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
perc.alumni
</td>
<td>
</td>
<td>
2.319<sup>***</sup>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
(0.879)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
Expend
</td>
<td>
</td>
<td>
0.003
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
(0.003)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
Grad.Rate
</td>
<td>
</td>
<td>
0.136
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
(0.648)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
Constant
</td>
<td>
86.881<sup>***</sup>
</td>
<td>
187.938<sup>**</sup>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
(20.984)
</td>
<td>
(89.615)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td colspan="3" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
Observations
</td>
<td>
622
</td>
<td>
622
</td>
</tr>
<tr>
<td style="text-align:left">
R<sup>2</sup>
</td>
<td>
0.820
</td>
<td>
0.956
</td>
</tr>
<tr>
<td style="text-align:left">
Adjusted R<sup>2</sup>
</td>
<td>
0.819
</td>
<td>
0.955
</td>
</tr>
<tr>
<td style="text-align:left">
Residual Std. Error
</td>
<td>
403.989 (df = 619)
</td>
<td>
202.349 (df = 604)
</td>
</tr>
<tr>
<td style="text-align:left">
F Statistic
</td>
<td>
1,405.761<sup>***</sup> (df = 2; 619)
</td>
<td>
768.822<sup>***</sup> (df = 17; 604)
</td>
</tr>
<tr>
<td colspan="3" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
<em>Note:</em>
</td>
<td colspan="2" style="text-align:right">
<sup><em></em></sup><em>p&lt;0.1; <sup><strong></strong></sup><strong>p&lt;0.05; <sup></sup></strong></em>p&lt;0.01
</td>
</tr>

</tbody></table>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">Copyright 2025, Jacob Jameson</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>



</body></html>