<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Jacob Jameson">

<title>Jacob Jameson - Section 9 - Support Vector Machines</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="twitter:title" content="Jacob Jameson - Section 9 - Support Vector Machines">
<meta name="twitter:description" content="">
<meta name="twitter:image" content="https://www.jacobjameson.com/api 222 files/section 9/images/profile.png">
<meta name="twitter:creator" content="@JacobCJameson">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../images/sig.png" alt="" class="navbar-logo">
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/jacob-jameson" rel="" target="_blank"><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/JacobCJameson" rel="" target="_blank"><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/jacobjameson" rel="" target="_blank"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../posts/blog.html" rel="" target="">
 <span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-teaching" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Teaching</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-teaching">    
        <li>
    <a class="dropdown-item" href="../../teaching.html" rel="" target="">
 <span class="dropdown-text">Jacob’s Teaching Experience</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../R files/Intro R.html" rel="" target="">
 <span class="dropdown-text">Introduction to R</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../git files/Intro Git.html" rel="" target="">
 <span class="dropdown-text">Introduction to Git/GitHub</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../api 222 files/API222.html" rel="" target="">
 <span class="dropdown-text">API 222 Section Material</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../research.html" rel="" target="">
 <span class="menu-text">Research</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#notes" id="toc-notes" class="nav-link active" data-scroll-target="#notes">Notes</a>
  <ul class="collapse">
  <li><a href="#support-vector-machines" id="toc-support-vector-machines" class="nav-link" data-scroll-target="#support-vector-machines">Support Vector Machines</a></li>
  <li><a href="#maximal-margin-classifier" id="toc-maximal-margin-classifier" class="nav-link" data-scroll-target="#maximal-margin-classifier">Maximal Margin Classifier</a></li>
  <li><a href="#separating-hyperplanes" id="toc-separating-hyperplanes" class="nav-link" data-scroll-target="#separating-hyperplanes">Separating Hyperplanes</a>
  <ul class="collapse">
  <li><a href="#classifications-with-separating-hyperplanes" id="toc-classifications-with-separating-hyperplanes" class="nav-link" data-scroll-target="#classifications-with-separating-hyperplanes">Classifications with Separating Hyperplanes</a></li>
  <li><a href="#maximal-margin-classifier-1" id="toc-maximal-margin-classifier-1" class="nav-link" data-scroll-target="#maximal-margin-classifier-1">Maximal Margin Classifier</a></li>
  </ul></li>
  <li><a href="#support-vector-classifier" id="toc-support-vector-classifier" class="nav-link" data-scroll-target="#support-vector-classifier">Support Vector Classifier</a></li>
  <li><a href="#support-vector-machine" id="toc-support-vector-machine" class="nav-link" data-scroll-target="#support-vector-machine">Support Vector Machine</a></li>
  <li><a href="#extensions-to-multiclass-problems" id="toc-extensions-to-multiclass-problems" class="nav-link" data-scroll-target="#extensions-to-multiclass-problems">Extensions to Multiclass Problems</a></li>
  </ul></li>
  <li><a href="#code" id="toc-code" class="nav-link" data-scroll-target="#code">Code</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content column-page-right" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Section 9 - Support Vector Machines</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Jacob Jameson </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<section id="notes" class="level1">
<h1>Notes</h1>
<p>Note that the material in these notes draws on the excellent past notes by TFs Laura Morris, Emily Mower and more thorough treatment of these topics in by Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani.</p>
<section id="support-vector-machines" class="level2">
<h2 class="anchored" data-anchor-id="support-vector-machines">Support Vector Machines</h2>
<p>In this class, we will see a series of methods that fall under the support vector umbrella but which vary significantly in their flexibility. We start with maximal margin classifiers, which are the most rigid and only work when the data can be perfectly separated with a linear decision boundary. Then, we will cover support vector classifiers, which still uses a linear decision boundary, but which can accommodate data that cannot be perfectly separated by such a decision boundary. We will then cover support vector machines, which flexibly transform the original data to allow for decision boundaries that are non-linear in the original feature space (though they remain linear in the transformed feature space). Like support vector classifiers, support vector machines will also accommodate data that is not perfectly separable. Finally, we will touch upon extending the support vector ideas to multiclass settings.</p>
</section>
<section id="maximal-margin-classifier" class="level2">
<h2 class="anchored" data-anchor-id="maximal-margin-classifier">Maximal Margin Classifier</h2>
<p>Maximal margin classifiers use a separating hyperplane to divide the feature space in two, with the idea being that all observations in one class lie on one side of the separating hyperplane while all observations of the other class lie on the other side.</p>
</section>
<section id="separating-hyperplanes" class="level2">
<h2 class="anchored" data-anchor-id="separating-hyperplanes">Separating Hyperplanes</h2>
<p>A hyperplane is a flat affine subspace that has one fewer dimensions than the feature space. The first part of the definition (“flat affine subspace”) means that the subspace can be described by a linear equation and does not need to pass through the origin. The second part of the definition (about the dimensionality) means that with <span class="math inline">\(p\)</span> features, the hyperplane will have <span class="math inline">\(p-1\)</span> dimensions. When we say “separating hyperplane,” we mean a hyperplane that separates the observations in one class from observations in the other by slicing the feature space in two.</p>
<p>Imagine a dataset with only two features, <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>. The feature space is a plane, which can be divided by a line (which is a hyperplane). Suppose you had three features, <span class="math inline">\(X_1\)</span>, <span class="math inline">\(X_2\)</span>, and <span class="math inline">\(X_3\)</span>. The feature space is 3D and can be divided in two by a plane (which is also a hyperplane). We can continue to generalize to higher dimensional feature spaces.</p>
<p>The separating hyperplane that divides the feature space with <span class="math inline">\(p\)</span> features can be described by a linear function of the following form</p>
<p><span class="math display">\[
\beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_p x_p = 0
\]</span></p>
<section id="classifications-with-separating-hyperplanes" class="level3">
<h3 class="anchored" data-anchor-id="classifications-with-separating-hyperplanes">Classifications with Separating Hyperplanes</h3>
<p>We can then use this equation as our classifier. Specifically, let <span class="math inline">\(f(x)\)</span> represent the left hand side of the previous equation. To identify the class for observation <span class="math inline">\(x^\star\)</span>, you first calculate <span class="math inline">\(f(x^\star)\)</span></p>
<p><span class="math display">\[
f(x^*) = \beta_0 + \beta_1 x_1^* + \beta_2 x_2^* + ... + \beta_p x_p^*
\]</span></p>
<p>If the resulting value is negative, the point lies to one side of the hyperplane and is assigned to class <span class="math inline">\(y=-1\)</span>. If it’s positive, the point lies on the other side of the hyperplane and is assigned to class <span class="math inline">\(y=+1\)</span>. If the point is far from the separating hyperplane, we are quite confident in our classification. If it’s close, we have much more uncertainty. In this sense, the sign of <span class="math inline">\(f(x^\star)\)</span> gives us the class and the magnitude of <span class="math inline">\(f(x^\star)\)</span> gives us our level of confidence. Given the linear form of the separating hyperplane, the decision boundary will also be linear.</p>
<p>Note that we are now using <span class="math inline">\(+1\)</span> and <span class="math inline">\(-1\)</span> for our binary classes, whereas up to this point we have used <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span>.</p>
</section>
<section id="maximal-margin-classifier-1" class="level3">
<h3 class="anchored" data-anchor-id="maximal-margin-classifier-1">Maximal Margin Classifier</h3>
<p>The maximal margin classifier can be used when the data is perfectly separable, meaning that there exists a separating hyperplane such that all observations from one class fall on one side of the hyperplane and all observations from the other class fall on the other side of the hyperplane. However, when one such separating hyperplane exists, usually infinite such separating hyperplanes exist. The maximal margin classifier provides a disciplined way to choose among them.</p>
<p>Specifically, it measures the distance between each point and the separating hyperplane. The minimum distance between all points and the separating hyperplane is referred to as the margin. The maximal margin classifier selects that separating hyperplane that leads to the largest possible margin, that is, the largest possible distance between the separating hyperplane and the closest training points. Note that as you increase the distance between the decision boundary and the closest point from one class, you must decrease the distance between the decision boundary and the closest point(s) from the other class. Therefore, the margin will always be defined by at least one point from each class. These points are called ``support’’ points or vectors and the model is fully defined by them, so if they move the model changes. Other points can move however they like outside the margins, and as long as they do not cross the margins, the model will not change.</p>
<p>When the margin is large, it suggests the classes are very well separated and performance on a test set should be good. When the margin is small, the classes are only barely separated and the exact decision boundary may not do as well in the test set.</p>
</section>
</section>
<section id="support-vector-classifier" class="level2">
<h2 class="anchored" data-anchor-id="support-vector-classifier">Support Vector Classifier</h2>
<p>Sometimes the data cannot be perfectly separated by a separating hyperplane. In such cases, the support vector classifier offers a generalization of the maximal margin classifier.</p>
<p>The support vector classifier is extremely similar to the maximal margin classifier, except that it allows some points to cross the margin and even the decision boundary (e.g.&nbsp;be misclassified). Because some points can cross the margin under the support vector classifier, we call the margin a “soft margin” compared to the “hard margin” of the maximal margin classifier, which does not permit any points to cross it.</p>
<p>The support vector classifier improves empirically relative to the maximal margin classifier in three key ways. One, it works for data that cannot be perfectly separated by a hyperplane. Two, it is more robust to individual points, meaning that because it allows points to cross the margin, movement in points near the margin will not have the same dramatic impact on the margin and decision boundary that they would have had under the maximal margin classifier. Third, related to this point, the support vector classifier yields better predictions for most training observations.</p>
<p>The support vector classifier works by creating slack variables <span class="math inline">\(\epsilon_i\)</span> and allowing a misclassification “budget” <span class="math inline">\(C\)</span>. The slack variables <span class="math inline">\(\epsilon_i\)</span> will be zero for all observations that fall on the correct side of the margin. If the observation is on the wrong side of the margin, <span class="math inline">\(\epsilon_i &gt; 0\)</span> and if it is on the wrong side of the hyperplane, <span class="math inline">\(\epsilon_i &gt; 1\)</span>. The sum of the <span class="math inline">\(\epsilon_i\)</span>s must be no greater than the budget <span class="math inline">\(C\)</span>, so when the budget <span class="math inline">\(C=0\)</span>, no observations will be allowed on the wrong side of the margin. In this way, the maximal margin classifier is a special case of the support vector classifier. More generally, no more than <span class="math inline">\(C\)</span> observations can be misclassified, because <span class="math inline">\(\epsilon_i&gt;1\)</span> when the observation is misclassified and <span class="math inline">\(C\)</span> is the sum of the <span class="math inline">\(\epsilon_i\)</span>’s.</p>
<p>The budget <span class="math inline">\(C\)</span> can be seen as a tuning parameter and is thus generally found through cross-validation. As <span class="math inline">\(C\)</span> goes to zero, the classifier converges to the maximal margin classifier, so it is less tolerant of violations across the margin and thus the margins will shrink. As <span class="math inline">\(C\)</span> gets large, it will become more tolerant of violations and the margin will increase.</p>
<p>In the support vector classifier, only observations that lie on the margin or that violate the margin will affect the hyperplane. Just as with the maximal margin classifier, points that lie on the correct side of the margin will not be used to define the hyperplane. As <span class="math inline">\(C\)</span> increases, there are more violations and so more support vectors compared to when <span class="math inline">\(C\)</span> is small. Given that there are more support vectors used when <span class="math inline">\(C\)</span> is large, large <span class="math inline">\(C\)</span> leads to lower variance though higher bias compared to small <span class="math inline">\(C\)</span> (which uses a small number of support vectors). Intuitively, this is because the model is not as sensitive to the exact training points since more of them are used in defining the hyperplane when <span class="math inline">\(C\)</span> is large.</p>
</section>
<section id="support-vector-machine" class="level2">
<h2 class="anchored" data-anchor-id="support-vector-machine">Support Vector Machine</h2>
<p>The support vector machine extends the support vector classifier to the case where the decision boundary is non-linear. It is somewhat analogous to using polynomial regression when the linearity assumption of linear regression does not hold. Specifically, it works with a transformed feature space and finds a decision boundary that is linear in the transformed space, but which is non-linear in the original space.</p>
<p>However, the way in which the support vector machine transforms the original space is new. It does the transformation using a kernel <span class="math inline">\(K(x_i, x_{i^\prime})\)</span>, which is a generalization of the inner product <span class="math inline">\(&lt;x_i,x_{i^\prime}&gt;\)</span> (e.g.&nbsp;dot product). The hyperplane is then defined by</p>
<p><span class="math display">\[
    f(x) = \beta_0 + \sum_{i\in \mathcal{S}}\alpha_i K(x,x_i)
\]</span></p>
<p>The values of <span class="math inline">\(\alpha_i\)</span> are only non-zero for support vectors (points that lie on or across the margin). Some popular kernels include the polynomial kernel and the radial kernel. Note that the support vector classifier is a special case of the support vector machine where the kernel is a polynomial kernel of degree <span class="math inline">\(d=1\)</span>. Just like the support vector classifier, it maintains the principle of a budget <span class="math inline">\(C\)</span>, though now we use <span class="math inline">\(\alpha_i\)</span> instead of <span class="math inline">\(\epsilon_i\)</span>.</p>
<p>The argument for why we use a kernel rather than an enlarged feature space has to do with computational efficiency. Using the kernel only requires computing the kernel (the generalized inner product) for each unique pair $(x_i, x_{i^}) $ in the training data; it does not require explicitly working in a transformed feature space, which may be computationally intractable. For example, suppose we wanted to expand our feature space from <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> to also include <span class="math inline">\(x_3 = x_1^2 + x_2^2\)</span>. Instead of explicitly calculating <span class="math inline">\(x_3\)</span>, we only need to adjust the inner product between two points <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> from</p>
<p><span class="math display">\[
K(a,b) = x_{1,a}x_{1,b}+x_{2,a}x_{2,b}
\]</span></p>
<p>to</p>
<p><span class="math display">\[
K(a,b) = x_{1,a}x_{1,b}+x_{2,a}x_{2,b} +
    (x_{1,a}^2 + x_{1,b}^2)(x_{2,a}^2 + x_{2,b}^2)
\]</span></p>
<p>The kernel function can take many forms, including polynomial and radial functions. Different kernel functions allow for different levels of model flexibility. However, note that as with many other models we’ve seen this semester, the more flexible we make the kernel, the more likely we are to fit the training data well (low bias) but risk overfitting the training data (high variance). Therefore, in the support vector machine, a very flexible kernel function leads to low bias but high variance.</p>
</section>
<section id="extensions-to-multiclass-problems" class="level2">
<h2 class="anchored" data-anchor-id="extensions-to-multiclass-problems">Extensions to Multiclass Problems</h2>
<p>The idea of support vector machines does not generalize easily to the multiclass setting, but two options have been proposed.</p>
<p>One is called the <em>one-versus-one</em> approach, where a collection of models is built that each evaluate the question of whether the observation belongs to class <span class="math inline">\(a\)</span> or class <span class="math inline">\(b\)</span>. This is repeated with all possible pairs of classes in the data. For a given test point, you tally how many times the observation is assigned to each of the <span class="math inline">\(K\)</span> classes and assign whichever class was assigned most often.</p>
<p>The other is called the <em>one-versus-all</em> approach, where <span class="math inline">\(K\)</span> models are built and each model compares the class at hand to a collection of the other <span class="math inline">\(K-1\)</span> classes, coded collectively as -1. For a given test point, you determine which <span class="math inline">\(f_k(x)\)</span> is largest (most confidence) and assign that class.</p>
</section>
</section>
<section id="code" class="level1">
<h1>Code</h1>
<p>This week, we will use the College data that is part of the ISLR package</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ISLR)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>college_data <span class="ot">&lt;-</span> College</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We will start by fitting a support vector classifier to the College data. The College data has 18 variables. We will treat “Private” as the outcome variable and the acceptance rates and out-of-state tuition as features. Since the first variable currently exists as a count (not rate), we begin by creating the new variable. To do this, we will use the dplyr package. Note: if your code won’t run, make sure your MASS package isn’t loaded.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>transformed_data <span class="ot">&lt;-</span> college_data <span class="sc">%&gt;%</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">accept_rate =</span> Accept<span class="sc">/</span>Apps) <span class="sc">%&gt;%</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">select</span>(accept_rate, Outstate, Private)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The svm function will have a hard time unless we scale our data. There is an option to scale within the <code>svm()</code> function that is perfectly sufficient when training a model. However, we will be doing a lot of visual inspection, so it will help to have our raw data scaled for these exercises.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>transformed_data <span class="ot">&lt;-</span> transformed_data <span class="sc">%&gt;%</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">accept_rate =</span> <span class="fu">scale</span>(accept_rate),</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">Outstate =</span> <span class="fu">scale</span>(Outstate))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To help with visual interpretation, we will take a random subset of the full data to use in most examples</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">222</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>small_data <span class="ot">&lt;-</span> transformed_data[<span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(transformed_data), <span class="dv">100</span>),]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Later, it will be convenient to have the features in their own matrix and the outcome in its own vector, so we do that now</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(small_data[, <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>])</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">if_else</span>(small_data[, <span class="dv">3</span>] <span class="sc">==</span> <span class="st">"Yes"</span>, <span class="dv">1</span>, <span class="sc">-</span><span class="dv">1</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(transformed_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   accept_rate.V1        Outstate.V1      Private  
 Min.   :-4.027367   Min.   :-2.0135809   No :212  
 1st Qu.:-0.484557   1st Qu.:-0.7757038   Yes:565  
 Median : 0.216325   Median :-0.1120227            
 Mean   : 0.000000   Mean   : 0.0000000            
 3rd Qu.: 0.690631   3rd Qu.: 0.6175294            
 Max.   : 1.720364   Max.   : 2.7987285            </code></pre>
</div>
</div>
<p>We will start by looking at our data, where the color represents whether the college is private or public</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(small_data[, <span class="fu">c</span>(<span class="st">"accept_rate"</span>, <span class="st">"Outstate"</span>)], </span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">col =</span> small_data<span class="sc">$</span>Private)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="section-9_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Clearly, our data is not perfectly separable, so we cannot use the maximal margin classifier. Let’s try a support vector classifier. For this, we use the package e1071, which implements support vector machines in R. Recall that the support vector classifier is a special case of the support vector machine where the kernel is linear. We have been talking about a “budget” for points that violate the margin or decision boundary. This package uses “cost”, which is basically the inverse – how much should an error cost? If we want to allow a big budget, that translates to using a small cost parameter. The default cost is 1.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages("e1071")</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(e1071)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>college_svm1 <span class="ot">&lt;-</span> <span class="fu">svm</span>(Private <span class="sc">~</span> Outstate <span class="sc">+</span> accept_rate, </span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>                    <span class="at">data =</span> small_data,</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>                    <span class="at">kernel =</span> <span class="st">"linear"</span>,</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>                    <span class="at">cost =</span> <span class="dv">10</span>,</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>                    <span class="at">scale =</span> <span class="cn">FALSE</span>)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(college_svm1, small_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="section-9_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>There are a few main things we can see from this plot:</p>
<ul>
<li><ol type="1">
<li>The decision boundary, which is linear even though it looks jagged</li>
</ol></li>
<li><ol start="2" type="1">
<li>The support vectors (x’s) and all other points (o’s)</li>
</ol></li>
<li><ol start="3" type="1">
<li>The regions where the model predicts “Yes” and “No”</li>
</ol></li>
</ul>
<p>We can also learn about our model using <code>summary()</code></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(college_svm1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
svm(formula = Private ~ Outstate + accept_rate, data = small_data, 
    kernel = "linear", cost = 10, scale = FALSE)


Parameters:
   SVM-Type:  C-classification 
 SVM-Kernel:  linear 
       cost:  10 

Number of Support Vectors:  32

 ( 16 16 )


Number of Classes:  2 

Levels: 
 No Yes</code></pre>
</div>
</div>
<p>From this output, we see: - (1) The number of support vectors, total and in each class - (2) The type of kernel (“linear”) and cost (10)</p>
<p>We can find which points serve as support vectors by getting their row numbers. Note that the “Yes” SV indices are listed first, followed by the “No” SV indices</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>college_svm1<span class="sc">$</span>index</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1]  8 12 15 21 24 31 32 39 50 52 56 61 62 65 92 94  4  6  7 10 17 25 40 70 71
[26] 72 74 75 87 88 95 98</code></pre>
</div>
</div>
<p>The svm() function in R does not immediately return the coefficients for the support vector classifier. It is believed that the reason for this is that the function is a very general function and the linear kernel used for the support vector classifier is only one of the many kernels it can handle. However, thanks to code from Data Camp, we can recover the the coefficients. Note that rho actually gives -beta0 “t” in line 100 below stands for transpose, “drop” get rid off redundant dimensions. See link below for more information https://statisticsglobe.com/drop-function-r</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>beta <span class="ot">&lt;-</span> <span class="fu">drop</span>(<span class="fu">t</span>(college_svm1<span class="sc">$</span>coefs) <span class="sc">%*%</span> x[college_svm1<span class="sc">$</span>index,])</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>beta0 <span class="ot">&lt;-</span> <span class="sc">-</span>college_svm1<span class="sc">$</span>rho</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(beta)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>accept_rate    Outstate 
  0.7777781   2.6005940 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(beta0)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.749692</code></pre>
</div>
</div>
<p>To understand our model better, we will:</p>
<ul>
<li><ol type="1">
<li>Create a grid of x-values that cover our feature space</li>
</ol></li>
<li><ol start="2" type="1">
<li>Predict a class for each point on the grid to get shading</li>
</ol></li>
<li><ol start="3" type="1">
<li>Plot our points and highlight support vectors</li>
</ol></li>
<li><ol start="4" type="1">
<li>Plot the decision boundary and margins</li>
</ol></li>
</ul>
<p>For 1, I will us a function provided by Data Camp:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>make.grid <span class="ot">=</span> <span class="cf">function</span>(x, <span class="at">n =</span> <span class="dv">75</span>) {</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>  grange <span class="ot">&lt;-</span>  <span class="fu">apply</span>(x, <span class="dv">2</span>, range)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>  x1 <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> grange[<span class="dv">1</span>, <span class="dv">1</span>], <span class="at">to =</span> grange[<span class="dv">2</span>, <span class="dv">1</span>], <span class="at">length =</span> n)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>  x2 <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> grange[<span class="dv">1</span>, <span class="dv">2</span>], <span class="at">to =</span> grange[<span class="dv">2</span>, <span class="dv">2</span>], <span class="at">length =</span> n)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">expand.grid</span>(<span class="at">X1 =</span> x1, <span class="at">X2 =</span> x2)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>xgrid <span class="ot">&lt;-</span> <span class="fu">make.grid</span>(x)</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(xgrid) <span class="ot">&lt;-</span> <span class="fu">colnames</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>For 2, we will use the predict() function to get the class for each point on the grid</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>ygrid <span class="ot">&lt;-</span> <span class="fu">predict</span>(college_svm1, xgrid)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>For 3, we will plot the grid, then the points, then the support vectors</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(xgrid, </span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"red"</span>,<span class="st">"blue"</span>)[<span class="fu">as.numeric</span>(ygrid)], </span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">pch =</span> <span class="dv">20</span>, </span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">cex =</span> .<span class="dv">2</span>)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x, </span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> y <span class="sc">+</span> <span class="dv">3</span>, </span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>       <span class="at">pch =</span> <span class="dv">19</span>)</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x[college_svm1<span class="sc">$</span>index,], </span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>       <span class="at">pch =</span> <span class="dv">5</span>, </span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>       <span class="at">cex =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="section-9_files/figure-html/unnamed-chunk-13-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>For (4), we can use the function abline, which takes the intercept and slope of a line. Recall that the coefficients we have recovered are of the form b0 + b1 * x1 + b2 * x2 = 0. To convert that to the abline form, we do some elementary math:</p>
<p>[b_2 * x_2 = -b_0 - b_1 * x_1]</p>
<p>[x_2 = ]</p>
<p>So the intercept is <span class="math inline">\(-b_0/b_2\)</span> and the slope is <span class="math inline">\(-b_1/b_2\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(xgrid, </span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"red"</span>,<span class="st">"blue"</span>)[<span class="fu">as.numeric</span>(ygrid)], </span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">pch =</span> <span class="dv">20</span>, </span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">cex =</span> .<span class="dv">2</span>)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x, </span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> y <span class="sc">+</span> <span class="dv">3</span>, </span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>       <span class="at">pch =</span> <span class="dv">19</span>)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x[college_svm1<span class="sc">$</span>index,], </span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>       <span class="at">pch =</span> <span class="dv">5</span>, </span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>       <span class="at">cex =</span> <span class="dv">2</span>)</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="sc">-</span>beta0 <span class="sc">/</span> beta[<span class="dv">2</span>], <span class="sc">-</span>beta[<span class="dv">1</span>]<span class="sc">/</span>beta[<span class="dv">2</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="section-9_files/figure-html/unnamed-chunk-14-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>The margins have the same slope as the decision boundary but a different intercept. Under the formulation used by the svm() function and described on page 357 of ISLR, the margin equals 1 (that’s the vertical distance between the decision boundary and the margin lines). Thus, we want the intercept of the lines:</p>
<p>[b_0 + b_1 * x_1 + b_2 * x_2 = ]</p>
<p>[x_2 = ]</p>
<p>[x_2 = - * x_1]</p>
<p>So, the intercepts are <span class="math inline">\((\pm 1 - b_0) / b_2\)</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(xgrid, </span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"red"</span>,<span class="st">"blue"</span>)[<span class="fu">as.numeric</span>(ygrid)], </span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">pch =</span> <span class="dv">20</span>, </span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">cex =</span> .<span class="dv">2</span>)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x, </span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> y <span class="sc">+</span> <span class="dv">3</span>, </span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>       <span class="at">pch =</span> <span class="dv">19</span>)</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x[college_svm1<span class="sc">$</span>index,], </span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>       <span class="at">pch =</span> <span class="dv">5</span>, </span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>       <span class="at">cex =</span> <span class="dv">2</span>)</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>((<span class="sc">-</span><span class="dv">1</span> <span class="sc">-</span> beta0) <span class="sc">/</span> beta[<span class="dv">2</span>], <span class="sc">-</span>beta[<span class="dv">1</span>] <span class="sc">/</span> beta[<span class="dv">2</span>], <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>((<span class="sc">+</span><span class="dv">1</span> <span class="sc">-</span> beta0) <span class="sc">/</span> beta[<span class="dv">2</span>], <span class="sc">-</span>beta[<span class="dv">1</span>] <span class="sc">/</span> beta[<span class="dv">2</span>], <span class="at">lty =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="section-9_files/figure-html/unnamed-chunk-15-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Let’s see what happens if we decrease the cost of errors and repeat the same exercises. To make this easy to repeat for different cost values, we stick our code in a function.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>svm_cost <span class="ot">&lt;-</span> <span class="cf">function</span>(df, cost_val, xgrid) {</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>  svmfit <span class="ot">&lt;-</span> <span class="fu">svm</span>(Private <span class="sc">~</span> Outstate <span class="sc">+</span> accept_rate, </span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>                <span class="at">data =</span> df,</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>                <span class="at">kernel =</span> <span class="st">"linear"</span>,</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>                <span class="at">cost =</span> cost_val,</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>                <span class="at">scale =</span> <span class="cn">FALSE</span>)</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"# of support vectors ="</span>, <span class="fu">length</span>(svmfit<span class="sc">$</span>index)))</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>  beta <span class="ot">&lt;-</span> <span class="fu">drop</span>(<span class="fu">t</span>(svmfit<span class="sc">$</span>coefs) <span class="sc">%*%</span> x[svmfit<span class="sc">$</span>index,])</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>  beta0 <span class="ot">&lt;-</span> <span class="sc">-</span>svmfit<span class="sc">$</span>rho</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>  ygrid <span class="ot">&lt;-</span> <span class="fu">predict</span>(svmfit, xgrid)</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(xgrid, <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"red"</span>,<span class="st">"blue"</span>)[<span class="fu">as.numeric</span>(ygrid)], <span class="at">pch =</span> <span class="dv">20</span>, <span class="at">cex =</span> .<span class="dv">2</span>)</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">points</span>(x, <span class="at">col =</span> y <span class="sc">+</span> <span class="dv">3</span>, <span class="at">pch =</span> <span class="dv">19</span>)</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">points</span>(x[df<span class="sc">$</span>index,], <span class="at">pch =</span> <span class="dv">5</span>, <span class="at">cex =</span> <span class="dv">2</span>)</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">abline</span>(<span class="sc">-</span>beta0 <span class="sc">/</span> beta[<span class="dv">2</span>], <span class="sc">-</span>beta[<span class="dv">1</span>]<span class="sc">/</span>beta[<span class="dv">2</span>])</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">abline</span>((<span class="sc">-</span><span class="dv">1</span> <span class="sc">-</span> beta0) <span class="sc">/</span> beta[<span class="dv">2</span>], <span class="sc">-</span>beta[<span class="dv">1</span>] <span class="sc">/</span> beta[<span class="dv">2</span>], <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">abline</span>((<span class="sc">+</span><span class="dv">1</span> <span class="sc">-</span> beta0) <span class="sc">/</span> beta[<span class="dv">2</span>], <span class="sc">-</span>beta[<span class="dv">1</span>] <span class="sc">/</span> beta[<span class="dv">2</span>], <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Run the function svm_cost() using cost parameters 10, 1, 0.1, 0.01</p>
<p>Example:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">svm_cost</span>(small_data, .<span class="dv">01</span>, xgrid) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "# of support vectors = 57"</code></pre>
</div>
<div class="cell-output-display">
<p><img src="section-9_files/figure-html/unnamed-chunk-17-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>At first, the margins widen within the visible frame, but we can see that the decision boundary changes as we decrease the cost of errors. Additionally, as the cost of errors decrease, the number of support vectors increase.</p>
<p>While the visual exercise is useful in building intuition, often you will work with your full data set. In this case and in general, cross-validation is preferred to visual inspection. You can perform cross-validation to select among models using linear kernels by using the function <code>tune()</code></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">222</span>)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>tune_linear <span class="ot">&lt;-</span> <span class="fu">tune</span>(svm, </span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>                    Private <span class="sc">~</span> accept_rate <span class="sc">+</span> Outstate, </span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>                    <span class="at">data =</span> transformed_data,</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>                    <span class="at">kernel =</span> <span class="st">"linear"</span>,</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>                    <span class="at">ranges =</span> <span class="fu">list</span>(<span class="at">cost =</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">100</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can see which cost had the best performance and compare how cross-validation errors varied across cost values. In the case of our data set, performance levels off after cost = 1.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(tune_linear)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Parameter tuning of 'svm':

- sampling method: 10-fold cross validation 

- best parameters:
 cost
  0.1

- best performance: 0.1479687 

- Detailed performance results:
   cost     error dispersion
1 1e-03 0.2728938 0.03581616
2 1e-02 0.2150516 0.04654521
3 1e-01 0.1479687 0.03534060
4 1e+00 0.1479687 0.03258152
5 5e+00 0.1479687 0.03085414
6 1e+01 0.1492674 0.03148925
7 1e+02 0.1492674 0.03148925</code></pre>
</div>
</div>
<p>We can set the best model accordingly:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>best_linear_mod <span class="ot">&lt;-</span> tune_linear<span class="sc">$</span>best.model</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(best_linear_mod)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
best.tune(METHOD = svm, train.x = Private ~ accept_rate + Outstate, 
    data = transformed_data, ranges = list(cost = c(0.001, 0.01, 
        0.1, 1, 5, 10, 100)), kernel = "linear")


Parameters:
   SVM-Type:  C-classification 
 SVM-Kernel:  linear 
       cost:  0.1 

Number of Support Vectors:  328

 ( 164 164 )


Number of Classes:  2 

Levels: 
 No Yes</code></pre>
</div>
</div>
<p>As we’ve done with other models this semester, you could split your data into test and training data, train your model on the training data (including selecting a model) using cross-validation and then test its performance on the test data.</p>
<p>Remember that we used only two features. This was useful for visual inspection, but often you have access to many more features. What would happen if we ran the same model using all features available in the original data set college_data? Unsurprisingly, we can obtain much lower error with more features.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>tune_linear_full <span class="ot">&lt;-</span> <span class="fu">tune</span>(svm,</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>                         Private <span class="sc">~</span> .,</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>                         <span class="at">data =</span> college_data,</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>                         <span class="at">kernel =</span> <span class="st">"linear"</span>,</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>                         <span class="at">ranges =</span> <span class="fu">list</span>(<span class="at">cost =</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span>,</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>                                                <span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">100</span>)))</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(tune_linear_full)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Parameter tuning of 'svm':

- sampling method: 10-fold cross validation 

- best parameters:
 cost
    5

- best performance: 0.05401265 

- Detailed performance results:
   cost      error dispersion
1 1e-03 0.14673660 0.04776340
2 1e-02 0.07335997 0.03590371
3 1e-01 0.06565102 0.02678567
4 1e+00 0.05657676 0.02504778
5 5e+00 0.05401265 0.02162469
6 1e+01 0.05787546 0.02029151
7 1e+02 0.05915751 0.02023357</code></pre>
</div>
</div>
<p>Mayve we think that a non-linear decision boundary would be better suited for our data. Thus, we would apply the support vector machine with a non-linear kernel. Some options include setting the kernel to “polynomial”, where we specify the degree d or “radial”, where we specify the positive constant gamma (larger values of gamma lead to more flexible models). Let’s start simple with a 3rd degree polynomial.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>svm_poly3 <span class="ot">&lt;-</span> <span class="fu">svm</span>(Private <span class="sc">~</span> Outstate <span class="sc">+</span> accept_rate,</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>                 <span class="at">data =</span> small_data,</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>                 <span class="at">kernel =</span> <span class="st">"polynomial"</span>,</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>                 <span class="at">degree =</span> <span class="dv">3</span>,</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>                 <span class="at">cost =</span> <span class="dv">1</span>)</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(svm_poly3, small_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="section-9_files/figure-html/unnamed-chunk-22-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>As before we can make a nice image of the model boundaries using the grid of x-values</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>ygrid <span class="ot">&lt;-</span> <span class="fu">predict</span>(svm_poly3, xgrid)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(xgrid, <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"red"</span>,<span class="st">"blue"</span>)[<span class="fu">as.numeric</span>(ygrid)], </span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">pch =</span> <span class="dv">20</span>, <span class="at">cex =</span> .<span class="dv">2</span>)</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x, <span class="at">col =</span> y <span class="sc">+</span> <span class="dv">3</span>, <span class="at">pch =</span> <span class="dv">19</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="section-9_files/figure-html/unnamed-chunk-23-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>To plot the decision boundary, we first use the predict() function with an additional argument decision.values = TRUE. This adds an attribute to the output, which allows you to recover the predicted value (not just predicted class) for each unique value in the test set (the x-grid in this case).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>predicted_grid <span class="ot">&lt;-</span> <span class="fu">predict</span>(svm_poly3, xgrid, </span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>                          <span class="at">decision.values =</span> <span class="cn">TRUE</span>)</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>predicted_grid <span class="ot">&lt;-</span> <span class="fu">attributes</span>(predicted_grid)<span class="sc">$</span>decision</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can then plot the decision boundary using the contour() function with level = 0</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>ygrid <span class="ot">&lt;-</span> <span class="fu">predict</span>(svm_poly3, xgrid)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(xgrid, <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"red"</span>,<span class="st">"blue"</span>)[<span class="fu">as.numeric</span>(ygrid)], </span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">pch =</span> <span class="dv">20</span>, <span class="at">cex =</span> .<span class="dv">2</span>)</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x, <span class="at">col =</span> y <span class="sc">+</span> <span class="dv">3</span>, <span class="at">pch =</span> <span class="dv">19</span>)</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="fu">contour</span>(<span class="fu">unique</span>(xgrid[,<span class="dv">1</span>]), <span class="fu">unique</span>(xgrid[,<span class="dv">2</span>]), </span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>        <span class="fu">matrix</span>(predicted_grid, <span class="dv">75</span>, <span class="dv">75</span>), </span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>        <span class="at">level =</span> <span class="dv">0</span>, </span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>        <span class="at">add =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="section-9_files/figure-html/unnamed-chunk-25-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>As before, we can use the tune() function to see how different cost values compare. Try writing the tune function to test polynomials of degree 2 and 3 and with cost values of 0.001, 0.01, 1, 5, and 100:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">222</span>)</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>tune_poly <span class="ot">&lt;-</span> <span class="fu">tune</span>(svm, </span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>                  Private <span class="sc">~</span> ., </span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>                  <span class="at">data =</span> transformed_data,</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>                  <span class="at">kernel =</span> <span class="st">"polynomial"</span>,</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>                  <span class="at">ranges =</span> <span class="fu">list</span>(<span class="at">cost =</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">100</span>),</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>                                <span class="at">degree =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">3</span>)))</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(tune_poly)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Parameter tuning of 'svm':

- sampling method: 10-fold cross validation 

- best parameters:
 cost degree
  100      3

- best performance: 0.1867299 

- Detailed performance results:
    cost degree     error dispersion
1  1e-03      2 0.2728938 0.03581616
2  1e-01      2 0.2728938 0.03581616
3  1e+00      2 0.2728938 0.03581616
4  5e+00      2 0.2728938 0.03581616
5  1e+02      2 0.2728938 0.03581616
6  1e-03      3 0.2728938 0.03581616
7  1e-01      3 0.2098402 0.03360308
8  1e+00      3 0.1970196 0.04169226
9  5e+00      3 0.1879953 0.03498841
10 1e+02      3 0.1867299 0.03300264</code></pre>
</div>
</div>
<p>We can also try with a radial kernel</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">222</span>)</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>tune_radial <span class="ot">&lt;-</span> <span class="fu">tune</span>(svm, Private <span class="sc">~</span> ., </span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>                    <span class="at">data =</span> transformed_data,</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>                    <span class="at">kernel =</span> <span class="st">"radial"</span>,</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>                    <span class="at">ranges =</span> <span class="fu">list</span>(<span class="at">cost =</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">100</span>),</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>                                  <span class="at">gamma =</span> <span class="fu">c</span>(<span class="fl">0.0001</span>, <span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="dv">1</span>)))</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(tune_radial)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Parameter tuning of 'svm':

- sampling method: 10-fold cross validation 

- best parameters:
 cost gamma
  100     1

- best performance: 0.1428238 

- Detailed performance results:
    cost gamma     error dispersion
1  1e-03 1e-04 0.2728938 0.03581616
2  1e-01 1e-04 0.2728938 0.03581616
3  1e+00 1e-04 0.2728938 0.03581616
4  5e+00 1e-04 0.2728938 0.03581616
5  1e+02 1e-04 0.1609058 0.03184748
6  1e-03 1e-03 0.2728938 0.03581616
7  1e-01 1e-03 0.2728938 0.03581616
8  1e+00 1e-03 0.2728938 0.03581616
9  5e+00 1e-03 0.2150516 0.04654521
10 1e+02 1e-03 0.1466866 0.03533624
11 1e-03 1e-02 0.2728938 0.03581616
12 1e-01 1e-02 0.2728938 0.03581616
13 1e+00 1e-02 0.1596237 0.03126915
14 5e+00 1e-02 0.1505495 0.03573142
15 1e+02 1e-02 0.1492674 0.03090384
16 1e-03 1e-01 0.2728938 0.03581616
17 1e-01 1e-01 0.1660839 0.03899615
18 1e+00 1e-01 0.1531136 0.03485918
19 5e+00 1e-01 0.1518149 0.03706845
20 1e+02 1e-01 0.1505328 0.03353007
21 1e-03 1e+00 0.2728938 0.03581616
22 1e-01 1e+00 0.1531136 0.03787237
23 1e+00 1e+00 0.1505495 0.03246168
24 5e+00 1e+00 0.1428738 0.02609063
25 1e+02 1e+00 0.1428238 0.02848941</code></pre>
</div>
</div>
<p>Comparing cross-validation errors between the radial and polynomial fits, it seems that radial is better for our setting. Let’s understand how the radial decision boundary is drawn. Recall that after running tune() we can extract the best model</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>svm_radial <span class="ot">&lt;-</span> tune_radial<span class="sc">$</span>best.model</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Make predictions for the xgrid</span></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>ygrid <span class="ot">&lt;-</span> <span class="fu">predict</span>(svm_radial, xgrid)</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a><span class="do">## And plot the grid predictions and decision boundary</span></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(xgrid, <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"red"</span>,<span class="st">"blue"</span>)[<span class="fu">as.numeric</span>(ygrid)], </span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>     <span class="at">pch =</span> <span class="dv">20</span>, <span class="at">cex =</span> .<span class="dv">2</span>)</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x, <span class="at">col =</span> y <span class="sc">+</span> <span class="dv">3</span>, <span class="at">pch =</span> <span class="dv">19</span>)</span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>predicted_grid <span class="ot">&lt;-</span> <span class="fu">predict</span>(svm_radial, xgrid, <span class="at">decision.values =</span> <span class="cn">TRUE</span>)</span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>predicted_grid <span class="ot">&lt;-</span> <span class="fu">attributes</span>(predicted_grid)<span class="sc">$</span>decision</span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a><span class="fu">contour</span>(<span class="fu">unique</span>(xgrid[,<span class="dv">1</span>]), <span class="fu">unique</span>(xgrid[,<span class="dv">2</span>]), </span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a>        <span class="fu">matrix</span>(predicted_grid, <span class="dv">75</span>, <span class="dv">75</span>), <span class="at">level =</span> <span class="dv">0</span>, <span class="at">add =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="section-9_files/figure-html/unnamed-chunk-28-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Again, we can compare our radial and polynomial models on the two-feature data to the same models on the original full data set college_data.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>full_poly <span class="ot">&lt;-</span> <span class="fu">tune</span>(svm, </span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>                  Private <span class="sc">~</span> ., </span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">data =</span> college_data,</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>                  <span class="at">kernel =</span> <span class="st">"polynomial"</span>,</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>                  <span class="at">ranges =</span> <span class="fu">list</span>(<span class="at">cost =</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">100</span>),</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>                                <span class="at">degree =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">3</span>)))</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(full_poly)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Parameter tuning of 'svm':

- sampling method: 10-fold cross validation 

- best parameters:
 cost degree
    5      3

- best performance: 0.07462537 

- Detailed performance results:
    cost degree      error dispersion
1  1e-03      2 0.27157842 0.04464526
2  1e-01      2 0.20079920 0.04546786
3  1e+00      2 0.16345321 0.04062089
4  5e+00      2 0.14029304 0.03357035
5  1e+02      2 0.14157509 0.03847015
6  1e-03      3 0.25872461 0.03991465
7  1e-01      3 0.16861472 0.05260691
8  1e+00      3 0.08618049 0.03520954
9  5e+00      3 0.07462537 0.03297477
10 1e+02      3 0.09522145 0.02911267</code></pre>
</div>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(tune_poly)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Parameter tuning of 'svm':

- sampling method: 10-fold cross validation 

- best parameters:
 cost degree
  100      3

- best performance: 0.1867299 

- Detailed performance results:
    cost degree     error dispersion
1  1e-03      2 0.2728938 0.03581616
2  1e-01      2 0.2728938 0.03581616
3  1e+00      2 0.2728938 0.03581616
4  5e+00      2 0.2728938 0.03581616
5  1e+02      2 0.2728938 0.03581616
6  1e-03      3 0.2728938 0.03581616
7  1e-01      3 0.2098402 0.03360308
8  1e+00      3 0.1970196 0.04169226
9  5e+00      3 0.1879953 0.03498841
10 1e+02      3 0.1867299 0.03300264</code></pre>
</div>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>full_radial <span class="ot">&lt;-</span> <span class="fu">tune</span>(svm, </span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>                    Private <span class="sc">~</span> ., </span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>                    <span class="at">data =</span> college_data,</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>                    <span class="at">kernel =</span> <span class="st">"radial"</span>,</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>                    <span class="at">ranges =</span> <span class="fu">list</span>(<span class="at">cost =</span> <span class="fu">c</span>(<span class="fl">0.001</span>, <span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">100</span>),</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>                                  <span class="at">gamma =</span> <span class="fu">c</span>(<span class="fl">0.0001</span>, <span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="dv">1</span>)))</span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(full_radial)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Parameter tuning of 'svm':

- sampling method: 10-fold cross validation 

- best parameters:
 cost gamma
  100  0.01

- best performance: 0.05656011 

- Detailed performance results:
    cost gamma      error dispersion
1  1e-03 1e-04 0.27272727 0.05678760
2  1e-01 1e-04 0.27272727 0.05678760
3  1e+00 1e-04 0.27144522 0.05669836
4  5e+00 1e-04 0.14400599 0.05642052
5  1e+02 1e-04 0.06939727 0.03735527
6  1e-03 1e-03 0.27272727 0.05678760
7  1e-01 1e-03 0.27144522 0.05669836
8  1e+00 1e-03 0.10541126 0.04419069
9  5e+00 1e-03 0.06811522 0.03728823
10 1e+02 1e-03 0.06298701 0.02661123
11 1e-03 1e-02 0.27272727 0.05678760
12 1e-01 1e-02 0.11313686 0.04576357
13 1e+00 1e-02 0.06683317 0.03566760
14 5e+00 1e-02 0.06040626 0.02900692
15 1e+02 1e-02 0.05656011 0.02099165
16 1e-03 1e-01 0.27272727 0.05678760
17 1e-01 1e-01 0.10929071 0.04864422
18 1e+00 1e-01 0.06683317 0.02937271
19 5e+00 1e-01 0.07069597 0.03021775
20 1e+02 1e-01 0.07069597 0.03471769
21 1e-03 1e+00 0.27272727 0.05678760
22 1e-01 1e+00 0.27272727 0.05678760
23 1e+00 1e+00 0.26500167 0.06185452
24 5e+00 1e+00 0.24831835 0.05311922
25 1e+02 1e+00 0.24831835 0.05311922</code></pre>
</div>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(tune_radial)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Parameter tuning of 'svm':

- sampling method: 10-fold cross validation 

- best parameters:
 cost gamma
  100     1

- best performance: 0.1428238 

- Detailed performance results:
    cost gamma     error dispersion
1  1e-03 1e-04 0.2728938 0.03581616
2  1e-01 1e-04 0.2728938 0.03581616
3  1e+00 1e-04 0.2728938 0.03581616
4  5e+00 1e-04 0.2728938 0.03581616
5  1e+02 1e-04 0.1609058 0.03184748
6  1e-03 1e-03 0.2728938 0.03581616
7  1e-01 1e-03 0.2728938 0.03581616
8  1e+00 1e-03 0.2728938 0.03581616
9  5e+00 1e-03 0.2150516 0.04654521
10 1e+02 1e-03 0.1466866 0.03533624
11 1e-03 1e-02 0.2728938 0.03581616
12 1e-01 1e-02 0.2728938 0.03581616
13 1e+00 1e-02 0.1596237 0.03126915
14 5e+00 1e-02 0.1505495 0.03573142
15 1e+02 1e-02 0.1492674 0.03090384
16 1e-03 1e-01 0.2728938 0.03581616
17 1e-01 1e-01 0.1660839 0.03899615
18 1e+00 1e-01 0.1531136 0.03485918
19 5e+00 1e-01 0.1518149 0.03706845
20 1e+02 1e-01 0.1505328 0.03353007
21 1e-03 1e+00 0.2728938 0.03581616
22 1e-01 1e+00 0.1531136 0.03787237
23 1e+00 1e+00 0.1505495 0.03246168
24 5e+00 1e+00 0.1428738 0.02609063
25 1e+02 1e+00 0.1428238 0.02848941</code></pre>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">Copyright 2024, Jacob Jameson</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>



</body></html>