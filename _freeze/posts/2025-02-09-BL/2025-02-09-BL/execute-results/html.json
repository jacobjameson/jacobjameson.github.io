{
  "hash": "f0334e518850e33835290d3d2ff97cb7",
  "result": {
    "markdown": "---\ntitle: \"A Gentle Introduction to Bayesian Linear Regression in R\"\ndescription: \"This guide walks you through Bayesian linear regression in R and Stan, explaining how priors, likelihoods, and posteriors work in an intuitive and hands-on way.\"\nauthor: \"Jacob Jameson\"\ndate: \"2025-02-09\"\ncategories: [bayesian, regression]\noutput:\n  tufte::tufte_html: default\n  tufte::tufte_handout:\n    citation_package: natbib\n    latex_engine: xelatex\n  tufte::tufte_book:\n    citation_package: natbib\n    latex_engine: xelatex\nlink-citations: true\nreference-location: margin\ncomments:\n  utterances:\n    repo: jacobjameson/jacobjameson.github.io\nformat:\n  html:\n    toc: true\n    toc-location: left\npage-layout: full\n---\n\n\n## Introduction\n\nLinear regression is a fundamental tool for modeling relationships between an outcome variable and one or more predictors. Traditionally, we often do this via ordinary least squares (OLS). In the frequentist approach, we estimate regression coefficients by finding values that best explain the observed data. The uncertainty in these estimates is represented by confidence intervals (CIs), which describe the expected variation if we were to repeat the entire data-collection process many times.\n\nHowever, confidence intervals are often misinterpreted. Many people assume a 95% confidence interval means, \"There is a 95% probability that the true parameter lies within this interval.\" In reality, this is incorrect—CIs do not assign probabilities to parameters. Instead, they describe how often the interval would contain the true parameter across many repeated samples, which is not the way we typically think about uncertainty.\n\nIn contrast, Bayesian credible intervals behave the way we actually want these things to work. A 95% credible interval does mean that, given our observed data and model, \"There is a 95% probability that the true parameter lies within this range.\" This makes Bayesian inference particularly appealing when we want intuitive probability statements about our parameters.\n\nBayesian linear regression treats model parameters (e.g., intercept, slope) as random variables with their own probability distributions. Instead of producing a single \"best\" estimate for each coefficient, we derive a posterior distribution, which represents a range of possible values for each parameter, given both:\n\n- Our prior beliefs (before seeing the data)\n\n- The likelihood of the observed data under the model assumptions\n\nThe result is a credible interval, which gives us a direct probability statement about our parameters, making it a powerful tool in statistical modeling.\n\nIn this post, we’ll work through an example in R to see:\n\n- How the posterior distribution updates from the prior distribution.\n\n- How to visualize priors versus posteriors.\n\n- How to interpret Bayesian predictions (including posterior predictive distributions).\n\n---\n\n## 1. Simulate Some Data\n\nLet’s simulate a small dataset with a linear relationship. Suppose the “true” model is:\n\n$$\ny = \\beta_0 + \\beta_1 x + \\varepsilon\n$$\n\nwhere:\n\n- $\\beta_0 = 2.0$ (intercept),\n\n- $\\beta_1 = 3.5$ (slope),\n\n- $\\varepsilon \\sim \\text{Normal}(0,1)$ (noise).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(rstanarm)  # for Bayesian regression\n\nset.seed(42)\n\nn <- 50\nx <- seq(0, 5, length.out = n)\nbeta0_true <- 2.0\nbeta1_true <- 3.5\nsigma_true <- 1.0\n\n# Generate y\nnoise <- rnorm(n, mean = 0, sd = sigma_true)\ny <- beta0_true + beta1_true * x + noise\n\ndf <- data.frame(x, y)\nhead(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          x        y\n1 0.0000000 3.370958\n2 0.1020408 1.792445\n3 0.2040816 3.077414\n4 0.3061224 3.704291\n5 0.4081633 3.832840\n6 0.5102041 3.679590\n```\n:::\n:::\n\n\n\n### Quick Plot of the Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(df, aes(x=x, y=y)) +\n  geom_point(color = \"#008Fd5\", alpha = 0.9, size=2) +\n  geom_abline(intercept=beta0_true, slope=beta1_true, \n              color=\"red\", linetype=\"dashed\") +\n  theme_minimal(base_size = 15) +\n  labs(title=\"Simulated Data with True Regression Line\",\n       subtitle=\"Red dashed line = true relationship\")\n```\n\n::: {.cell-output-display}\n![](2025-02-09-BL_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n\n---\n\n## 2. Frequentist OLS for Reference\n\nFirst, we fit a simple OLS model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nols_model <- lm(y ~ x, data = df)\nsummary(ols_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = y ~ x, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.7403 -0.4366 -0.1193  0.8319  2.1072 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   2.3548     0.3175   7.416  1.7e-09 ***\nx             3.3438     0.1094  30.555  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.139 on 48 degrees of freedom\nMultiple R-squared:  0.9511,\tAdjusted R-squared:  0.9501 \nF-statistic: 933.6 on 1 and 48 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nWe get a point estimate for the intercept and slope plus confidence intervals.\n\n---\n\n## 3. Bayesian Linear Regression\n\nNow let’s do a Bayesian version via the `rstanarm` package. Under the hood, `stan_glm` uses weakly informative priors by default (you can customize these).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbayes_model <- stan_glm(y ~ x, data=df, \n                        chains=2, iter=2000, seed=42)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 0.024376 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 243.76 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.026 seconds (Warm-up)\nChain 1:                0.032 seconds (Sampling)\nChain 1:                0.058 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 3e-06 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.03 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.04 seconds (Warm-up)\nChain 2:                0.023 seconds (Sampling)\nChain 2:                0.063 seconds (Total)\nChain 2: \n```\n:::\n\n```{.r .cell-code}\nprint(bayes_model, digits=3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nstan_glm\n family:       gaussian [identity]\n formula:      y ~ x\n observations: 50\n predictors:   2\n------\n            Median MAD_SD\n(Intercept) 2.372  0.334 \nx           3.337  0.115 \n\nAuxiliary parameter(s):\n      Median MAD_SD\nsigma 1.156  0.117 \n\n------\n* For help interpreting the printed output see ?print.stanreg\n* For info on the priors used see ?prior_summary.stanreg\n```\n:::\n:::\n\n\nThe summary output gives us:\n\n- Posterior mean: The most likely value for each coefficient given the data.\n\n- Standard deviation: How uncertain we are about each estimate.\n\n- 95% credible interval: The range where the true coefficient likely falls with 95% probability.\n\n\nUnlike frequentist confidence intervals, which describe the long-run variability across repeated samples, Bayesian credible intervals provide a direct probability statement about our parameters.\n\n\n### 3.1 What Are Priors Here?\n\nBy default, `stan_glm(..., family = gaussian())` uses something akin to a *weakly informative* prior on the slope and intercept. This means the prior allows a wide range of possible values for the coefficients but discourages extremely large magnitudes. You can supply arguments like `prior`, `prior_intercept`, etc., or switch to `brms` for more flexible syntax.\n\n### 3.2 Posterior Summaries\n\nThe printed output typically gives us:\n\n- **mean**: Posterior mean of the parameter. \n\n- **sd**: Posterior standard deviation (akin to “uncertainty”).  \n\n- **2.5% / 97.5%**: Bounds of the 95% *credible interval*.\n\nWe can visualize these distributions:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(bayes_model, \n     plotfun = \"areas\",  \n     pars = c(\"(Intercept)\", \"x\"),  \n     include = TRUE, \n     prob = 0.95,  border = \"black\") + \n  theme_minimal(base_size = 15) + \n  labs(title = \"Posterior Distributions with 95% Credible Interval\",\n       x = \"Parameter Value\",\n       y = \"Density\")\n```\n\n::: {.cell-output-display}\n![](2025-02-09-BL_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nEach density plot is the posterior distribution for one parameter, showing the entire spread of plausible values given the model and data. The shaded areas give the 95% credible interval.\n\n---\n\n## 4. Explaining the Posterior More Explicitly\n\n### 4.1 Combining Prior and Likelihood\n\nFrom a conceptual standpoint, Bayesian regression says:\n\n$$\n\\text{Posterior}(\\beta_0, \\beta_1 \\mid \\text{data}) \n\\;\\propto\\;\n\\text{Prior}(\\beta_0, \\beta_1) \\;\\times\\; \n\\text{Likelihood}(\\text{data} \\mid \\beta_0, \\beta_1).\n$$\n\n1. **Prior**: What values of $\\beta_0, \\beta_1$ are plausible before seeing any data?  \n\n2. **Likelihood**: Given a candidate pair $(\\beta_0, \\beta_1)$, how well does it explain our observed $y$ values?  \n\n3. **Posterior**: The result of *multiplying* these together and renormalizing into a probability distribution.\n\nThe best way to see this in action is to do a “prior vs. posterior” plot for (say) the **slope**. Let’s do a quick example of customizing a prior so we can illustrate how it gets updated.\n\n#### 4.1.1 A Very Simple Custom Prior Example\n\nSuppose we suspect the slope is likely around 1.0, with a standard deviation of 2. That means slopes near 1 are more plausible, but we allow for a broad range. Likewise, for the intercept, maybe we suspect a prior mean of 0 with a standard deviation of 10.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncustom_bayes_model <- stan_glm(\n  y ~ x,\n  data = df,\n  prior = normal(location = 1, scale = 2, autoscale=FALSE),       # slope prior\n  prior_intercept = normal(location = 0, scale = 10, autoscale=FALSE),\n  chains=2, iter=2000, seed=123\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 1.3e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.13 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.023 seconds (Warm-up)\nChain 1:                0.036 seconds (Sampling)\nChain 1:                0.059 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 5e-06 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.022 seconds (Warm-up)\nChain 2:                0.037 seconds (Sampling)\nChain 2:                0.059 seconds (Total)\nChain 2: \n```\n:::\n\n```{.r .cell-code}\nprint(custom_bayes_model, digits=3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nstan_glm\n family:       gaussian [identity]\n formula:      y ~ x\n observations: 50\n predictors:   2\n------\n            Median MAD_SD\n(Intercept) 2.378  0.344 \nx           3.335  0.117 \n\nAuxiliary parameter(s):\n      Median MAD_SD\nsigma 1.156  0.116 \n\n------\n* For help interpreting the printed output see ?print.stanreg\n* For info on the priors used see ?prior_summary.stanreg\n```\n:::\n:::\n\n\n\n\nNow, let’s extract the prior and posterior draws and plot them. We can sample from the prior if we specify `prior_PD = TRUE` (prior predictive distribution).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Step 1: sample from prior only (no data used)\nprior_only_model <- stan_glm(\n  y ~ x,\n  data = df,\n  prior = normal(location = 1, scale = 2, autoscale=FALSE),\n  prior_intercept = normal(location = 0, scale = 10, autoscale=FALSE),\n  chains=2, iter=2000, seed=123,\n  prior_PD = TRUE   # <--- This means: ignore the likelihood of data\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 8e-06 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.024 seconds (Warm-up)\nChain 1:                0.025 seconds (Sampling)\nChain 1:                0.049 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 4e-06 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.04 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.013 seconds (Warm-up)\nChain 2:                0.041 seconds (Sampling)\nChain 2:                0.054 seconds (Total)\nChain 2: \n```\n:::\n\n```{.r .cell-code}\n# Extract draws\nprior_draws <- as.matrix(prior_only_model, pars=c(\"(Intercept)\",\"x\"))\npost_draws <- as.matrix(custom_bayes_model, pars=c(\"(Intercept)\",\"x\"))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(tidyr)\n\ndf_draws <- data.frame(\n  prior_slope  = prior_draws[,\"x\"],\n  post_slope   = post_draws[,\"x\"]\n)\n\ndf_long <- df_draws %>% \n  pivot_longer(cols = everything(), \n               names_to = \"distribution\", values_to=\"slope_value\") %>%\n  mutate(distribution = ifelse(\n    distribution == \"prior_slope\", \"Prior Distribution\", \n    \"Posterior Distribution\"))\n\nggplot(df_long, aes(x=slope_value, fill=distribution)) +\n  geom_density(alpha=0.4) +\n  scale_fill_manual(values=c(\"Prior Distribution\" = \"#D55E00\", \n                             \"Posterior Distribution\" = \"#0072B2\")) +\n  labs(title=\"Slope: Prior vs Posterior\",\n       x=\"Slope Value\", \n       fill = \"Distribution\") +\n  theme_minimal(base_size = 14)\n```\n\n::: {.cell-output-display}\n![](2025-02-09-BL_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n* The red or orange curve will show the prior distribution for the slope (centered near 1, quite wide).\n\n* The blue curve will show the posterior after seeing the data. Because our true slope is actually 3.5, you’ll see that the posterior is pulled far to the right of the prior’s center of 1. The data “pushes” the posterior to align with the actual effect in the data, reducing uncertainty.\n\n\n## Posterior Predictive Distribution: Why It Matters\n\nSo far, we’ve focused on estimating the posterior distribution of our regression parameters. However, in most real-world applications, we’re not just interested in estimating coefficients—we want to use our model to make predictions about future observations.\n\nIn a frequentist regression, we typically obtain a point prediction:\n\n$$\n\\hat{y}_* = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_*\n$$\n\nalong with a prediction interval that accounts for both residual variability and parameter uncertainty.\n\n### The Bayesian Approach: Uncertainty in Predictions\n\nIn Bayesian regression, we don’t just compute a single best guess for $y_*$—we generate an entire posterior predictive distribution, which tells us:\n\n1. The most likely values of $y_*$ based on our model.\n\n2. The full range of plausible values, incorporating both parameter uncertainty and residual variability.\n\n3. The probability of exceeding a critical threshold, which is extremely useful for decision-making.\n\nExample Use Case:\n\n- Suppose $x_* = 2.5$ represents the duration of a hospital stay, and $y_*$ represents the total cost of treatment (in thousands).  \n\n- A hospital administrator might ask:  \n\n  - *\"What is the probability that this patient’s costs will exceed $10,000?\"*\n  \n  - *\"How much uncertainty is there in our cost estimate?\"*  \n  \n- Instead of a single prediction, the Bayesian posterior predictive distribution provides a full range of possible outcomes, making it much more informative.\n\n### Simulating from the Posterior Predictive Distribution\n\nWe generate predictions for a new observation $x_*$ by **sampling from the posterior**:\n\n$$\ny_* \\sim \\text{Normal}(\\beta_0 + \\beta_1 x_*, \\sigma^2)\n$$\n\nwhere $\\beta_0, \\beta_1, \\sigma$ are drawn from their posterior distributions.\n\nLet’s compute this for $x_* = 2.5$ and visualize the range of plausible values for $y_*$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Posterior draws for intercept, slope, and sigma\npost_draws_full <- as.matrix(custom_bayes_model)\n\n# Function to simulate predictions from posterior\nsimulate_posterior_y <- function(x_star, n_sims=4000) {\n  idx_int <- which(colnames(post_draws_full)==\"(Intercept)\")\n  idx_slope <- which(colnames(post_draws_full)==\"x\")\n  idx_sigma <- which(colnames(post_draws_full)==\"sigma\")\n\n  intercept_samples <- post_draws_full[, idx_int]\n  slope_samples     <- post_draws_full[, idx_slope]\n  sigma_samples     <- post_draws_full[, idx_sigma]\n\n  # Compute predicted means, then sample from Normal(mean, sigma)\n  mu_star <- intercept_samples + slope_samples * x_star\n  y_sim <- rnorm(n_sims, mean=mu_star, sd=sigma_samples)\n  y_sim\n}\n\nx_star <- 2.5\ny_sim <- simulate_posterior_y(x_star)\n\n# Probability that y_* > 10\nmean(y_sim > 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.72675\n```\n:::\n:::\n\n\nA histogram of simulated outcomes shows the full range of possible $y_*$ values, allowing us to make probability-based decisions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\nggplot(data.frame(y_sim), aes(y_sim)) +\n  geom_histogram(bins=30, fill=\"#D55E00\", color=\"white\") +\n  theme_minimal(base_size = 14) +\n  geom_vline(xintercept=10, color=\"black\", linetype=\"solid\", size=1.5) +\n  labs(title=\"Posterior Predictive Distribution at x=2.5\",\n       subtitle=\"Black line = threshold of 10\",\n       x=\"Possible y* values\", y=\"Frequency\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n```\n:::\n\n::: {.cell-output-display}\n![](2025-02-09-BL_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nIn this case, the probability that $y_*$ exceeds $10,000 is approximately 73\\%. This information is crucial for making informed decisions about resource allocation, risk management, or policy interventions.\n\n## Key Takeaways: Why This Matters\n\nUnlike traditional frequentist regression, Bayesian posterior predictive distributions allow us to answer probabilistic questions about new data points:\n\n* Point Estimate + Full Uncertainty: Instead of a single predicted $y_*$, we get a distribution over plausible values.  \n\n* Probability-Based Decisions: We can compute the probability that an outcome exceeds (or falls below) a critical threshold.  \n\n* More Robust Uncertainty Quantification: Since we account for both parameter uncertainty and residual variance, our predictions are more realistic.  \n\n\n**Further Reading**:\n\n- *Introduction to Bayesian Statistics* by William Bolstad.  \n\n- *Bayesian Data Analysis* by Gelman et al.  \n\n- The `rstanarm`, `brms`, or `bayesplot` packages in R for specifying, fitting, and visualizing Bayesian models.\n\n\n\n",
    "supporting": [
      "2025-02-09-BL_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}